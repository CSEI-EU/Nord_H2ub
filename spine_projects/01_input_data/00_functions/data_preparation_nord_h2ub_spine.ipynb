{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ea4b8f-0ba4-4513-8872-53f4a538a0d3",
   "metadata": {},
   "source": [
    "# Data Preparation for the Nord_H2ub Spine Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa86773-4431-4a2f-9490-4b3cf0aa8d70",
   "metadata": {},
   "source": [
    "This jupyter notebook contains all routines for the preparation of the input data sources into a input data file for the model in Spine. \n",
    "\n",
    "**Authors:** Johannes Giehl (jfg.eco@cbs.dk), Dana Hentschel (djh.eco@cbs.dk), Lucia Ciprian (luc.eco@cbs.dk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8175ae-f246-4788-a309-c1a4890992f2",
   "metadata": {},
   "source": [
    "## General settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc68f78-3383-4889-bd9e-8b3e3e2f6c2e",
   "metadata": {},
   "source": [
    "### Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f47a1c-073f-46c0-8a4d-7dafb1716b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92141795-3716-404e-8e35-a096dcaa0c40",
   "metadata": {},
   "source": [
    "### Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23418a81-7e7c-47c4-afc1-805a5eb7aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data preparation functions\n",
    "# Determine the current working directory\n",
    "module_path = os.getcwd()\n",
    "\n",
    "if os.path.basename(module_path) != '00_functions':\n",
    "# Set the module path (adjust the relative path if necessary)\n",
    "    module_path = os.path.abspath(os.path.join(module_path, '00_functions'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "# Load the functions and methods from the corresponding file\n",
    "from nord_h2ub_data_preparation_functions import *\n",
    "from nord_h2ub_data_preparation_main_functions import *\n",
    "from nord_h2ub_data_preparation_helper_functions import *\n",
    "from nord_h2ub_data_preparation_investment_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50630f-868b-40f0-842e-c74d936b5d54",
   "metadata": {},
   "source": [
    "### Base parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f557c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should just be used when running it from the user interface\n",
    "with open(os.path.join(module_path, 'parameters.pkl'), 'rb') as file:\n",
    "    parameters = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b565675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not parameters:  \n",
    "    print(\"Warning: No parameters were injected. Using default parameters only.\")\n",
    "    # Optionally, you could provide some default initialization here.\n",
    "\n",
    "(year, start_date, end_date, area, product, powers, powers_capacities, scenario, frequency, \n",
    "    model_name, temporal_block, stochastic_scenario, stochastic_structure, \n",
    "    report_name, reports, \n",
    "    electrolyzer_type, des_segments_electrolyzer, \n",
    "    share_of_dh_price_cap, price_level_power, power_price_variance, \n",
    "    roll_forward_use, roll_forward_size, num_slices, datetime_index, \n",
    "    candidate_nonzero, investment_period_default, \n",
    "    investment_cost_params,\n",
    "    capacities_exisiting_params,\n",
    "    capacity_ASU, \n",
    "    capacity_Electrolyzer, capacity_Haber_Bosch_reactor, capacity_Fischer_Tropsch_unit, capacity_RWGS_unit, capacity_Methanol_Plant,\n",
    "    capacity_Electric_Steam_Boiler, capacity_anaerobic, capacity_biomethanation, capacity_co2_removal,\n",
    "    investment_limit_params) = set_parameters(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56b541-1fbd-4e7e-9cf3-2ff25f8da472",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b811bdc-ac7b-4cd7-8e32-8f84bda412a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to correct folders\n",
    "'''still not working if it is not started from this jupyter notebook'''\n",
    "# Input data\n",
    "excel_file_path = get_excel_file_path() + '/01_input_raw/'\n",
    "# Prepared input data\n",
    "output_file_path = get_excel_file_path() + '/02_input_prepared/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89169e64-f204-47bb-9a83-17156a4aefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set name of the relevant files\n",
    "\n",
    "Model_structure_file = '/Model_Data_Base_' + product + '.xlsx'\n",
    "efficiency_electrolyzer_file = '/Efficiency_Electrolyzers.xlsx'\n",
    "distric_heating_price_file = 'energy_prices/district_heating_price_cap.xlsx'\n",
    "investment_costs_file = '/investment_cost_overview/Investment_cost_overview.xlsx'\n",
    "mapping_file = '/methanol_object_mapping.xlsx'\n",
    "\n",
    "PV_data_availabilityfactors = 'PV_availability_factors_Kasso.xlsx'\n",
    "Wind_data_availabilityfactors = 'Wind_availability_factors_Kasso.xlsx'\n",
    "data_powerprices = 'Day_ahead_prices_' + str(year) + '.xlsx'\n",
    "grid_costs = 'energy_prices/grid_costs.xlsx'\n",
    "\n",
    "# Output file\n",
    "output_file_name = product + '_Input_prepared.xlsx'\n",
    "output_mapping_file_name = product + '_object_mapping.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d15fe8-064f-4c28-be28-8d924a4ba31b",
   "metadata": {},
   "source": [
    "\n",
    "## Workflow of the data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ad49f-470e-4b29-aa02-c7babb08befb",
   "metadata": {},
   "source": [
    "### General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c50f50c3-e43d-41c2-8158-75596632213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date index\n",
    "date_index = pd.date_range(start=start_date, end=end_date, freq='h')\n",
    "formatted_dates = date_index.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "df_formatted_dates = pd.DataFrame(formatted_dates, columns=['DateTime'])\n",
    "\n",
    "df_time = pd.DataFrame(df_formatted_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb746a-7cd3-4655-88cf-ac543b003918",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a42c5077-74ef-4f63-b6d9-4aa3c11aa878",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "\n",
    "# Model structure\n",
    "df_model_units_raw = pd.read_excel(excel_file_path + product + Model_structure_file, sheet_name='Units', index_col=None)\n",
    "df_model_connections_raw = pd.read_excel(excel_file_path + product + Model_structure_file, sheet_name='Connections', index_col=None)\n",
    "df_model_storages_raw = pd.read_excel(excel_file_path + product + Model_structure_file, sheet_name='Storages', index_col=None)\n",
    "\n",
    "# Variable efficiency\n",
    "df_efficiency_electrolyzer = pd.read_excel(excel_file_path + product + efficiency_electrolyzer_file, sheet_name='Efficiency_'+electrolyzer_type)\n",
    "\n",
    "# Availability factor\n",
    "df_PV_availabilityfactors_values = pd.read_excel(excel_file_path+PV_data_availabilityfactors, skiprows=2, usecols=[0,1,2,3,4,5])\n",
    "df_wind_availabilityfactors_values = pd.read_excel(excel_file_path+Wind_data_availabilityfactors, skiprows=2, usecols=[0,1,2,3])\n",
    "\n",
    "# Power prices\n",
    "df_powerprices_total_values = pd.read_excel(excel_file_path+data_powerprices)\n",
    "# Only extracting the prices from our earlier defined area\n",
    "df_powerprices_values = df_powerprices_total_values[df_powerprices_total_values['PriceArea'] == area]\n",
    "df_powerprices_values = df_powerprices_values.reset_index(drop=True)\n",
    "df_grid_costs = pd.read_excel(excel_file_path + grid_costs)\n",
    "\n",
    "# District heating prices\n",
    "df_district_heating_price = pd.read_excel(excel_file_path + distric_heating_price_file, sheet_name='Price_Cap_Calculation', index_col=None)\n",
    "\n",
    "# Investment costs\n",
    "df_investment_costs_raw = pd.read_excel(excel_file_path + investment_costs_file, sheet_name='Investment_Cost', index_col=None)\n",
    "\n",
    "# Mapping between entity and parameter name\n",
    "df_mapping = pd.read_excel(excel_file_path + product + mapping_file, sheet_name='Object_Mapping', index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2693fc2-fe36-47a1-9b08-00f73dd53b9f",
   "metadata": {},
   "source": [
    "### Adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28376bad-520d-4ab3-85ce-2d1cf91ac5e5",
   "metadata": {},
   "source": [
    "#### Adjust base elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "73594a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite capacities with set ones from dropdowns\n",
    "# Depends on what capacity is related to (input or output) -> needs to be done for products other than methanol!!!\n",
    "for index, row in df_model_units_raw.iterrows():\n",
    "    object_type = row['Object_type']\n",
    "    if object_type in ['PEM_Electrolyzer', 'AEC_Electrolyzer', 'SOEC_Electrolyzer']:\n",
    "        object_type = 'Electrolyzer'\n",
    "    \n",
    "    # Default capacity in/out: existing row\n",
    "    \n",
    "    # Check if external capacities given\n",
    "    pattern = re.compile(rf\"capacity_.*{object_type}\")\n",
    "    matching_vars = [var for var in globals() if pattern.match(var)]\n",
    "    \n",
    "    if matching_vars:\n",
    "        variable_name = matching_vars[0]\n",
    "        variable_value = globals()[variable_name]\n",
    "        \n",
    "        if variable_value is not None:\n",
    "            if object_type in ['Electrolyzer', 'Electric_Steam_Boiler']:\n",
    "                df_model_units_raw.at[index, 'Cap_Input1_existing'] = variable_value\n",
    "            else: df_model_units_raw.at[index, 'Cap_Output1_existing'] = variable_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "861e7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite power capacity value with value from powers_capacities set in dropdowns\n",
    "# Add missing power source if necessary\n",
    "\n",
    "# Step 1: Check and update for Solar plant\n",
    "if 'Solar plant' in powers_capacities and powers_capacities['Solar plant'] is not None:\n",
    "    if not (df_model_units_raw['Object_type'] == 'PV_plant').any():\n",
    "        new_row = {col: np.nan for col in df_model_units_raw.columns}  # Initialize all columns with NaN\n",
    "        new_row['Unit'] = 'PV_plant'\n",
    "        new_row['Object_type'] = 'PV_plant'\n",
    "        new_row['Output1'] = 'Power_Kasso'\n",
    "        new_row['Cap_Output1_existing'] = powers_capacities['Solar plant']\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        df_model_units_raw = pd.concat([df_model_units_raw, new_row_df], ignore_index = True)\n",
    "    else:\n",
    "        df_model_units_raw.loc[df_model_units_raw['Object_type'] == 'PV_plant', 'Cap_Output1_existing'] = powers_capacities['Solar plant']\n",
    "\n",
    "# Step 2: Check and update for Wind_onshore\n",
    "if 'Wind onshore' in powers_capacities and pd.notna(powers_capacities['Wind onshore']):\n",
    "    if not (df_model_units_raw['Object_type'] == 'Wind_onshore').any():\n",
    "        new_row = {col: np.nan for col in df_model_units_raw.columns}  # Initialize all columns with NaN\n",
    "        new_row['Unit'] = 'Wind_onshore'\n",
    "        new_row['Object_type'] = 'Wind_onshore'\n",
    "        new_row['Output1'] = 'Power_Kasso'\n",
    "        new_row['Cap_Output1_existing'] = powers_capacities['Wind onshore']\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        df_model_units_raw = pd.concat([df_model_units_raw, new_row_df], ignore_index = True)\n",
    "    else:\n",
    "        df_model_units_raw.loc[df_model_units_raw['Object_type'] == 'Wind_onshore', 'Cap_Output1_existing'] = powers_capacities['Wind onshore']\n",
    "\n",
    "# Step 3: Check and update for Wind_offshore\n",
    "if 'Wind offshore' in powers_capacities and pd.notna(powers_capacities['Wind offshore']):\n",
    "    if not (df_model_units_raw['Object_type'] == 'Wind_offshore').any():\n",
    "        new_row = {col: np.nan for col in df_model_units_raw.columns}  # Initialize all columns with NaN\n",
    "        new_row['Unit'] = 'Wind_offshore'\n",
    "        new_row['Object_type'] = 'Wind_offshore'\n",
    "        new_row['Output1'] = 'Power_Kasso'\n",
    "        new_row['Cap_Output1_existing'] = powers_capacities['Wind offshore']\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        df_model_units_raw = pd.concat([df_model_units_raw, new_row_df], ignore_index = True)\n",
    "    else:\n",
    "        df_model_units_raw.loc[df_model_units_raw['Object_type'] == 'Wind_offshore', 'Cap_Output1_existing'] = powers_capacities['Wind offshore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7dfe4eb9-681a-4574-8170-cdc08156460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some unnecessary information\n",
    "df_model_units = df_model_units_raw.drop(columns = ['Object_type']).copy()\n",
    "df_model_connections = df_model_connections_raw.drop(columns = ['Object_type']).copy()\n",
    "df_model_storages = df_model_storages_raw.drop(columns = ['Object_type']).copy()\n",
    "\n",
    "# Create mapping tables for object name to type\n",
    "df_model_units_mapping = df_model_units_raw[['Unit', 'Object_type']].copy()\n",
    "df_model_connections_mapping = df_model_connections_raw[['Connection', 'Object_type']].copy()\n",
    "df_model_storages_mapping = df_model_storages_raw[['Storage', 'Object_type']].copy()\n",
    "\n",
    "df_model_units_mapping.rename(columns={'Unit': 'Object_name'}, inplace=True)\n",
    "df_model_connections_mapping.rename(columns={'Connection': 'Object_name'}, inplace=True)\n",
    "df_model_storages_mapping.rename(columns={'Storage': 'Object_name'}, inplace=True)\n",
    "\n",
    "# Create a dataframe with mapping of all object in the model\n",
    "df_model_object_mapping = pd.concat([df_model_units_mapping, df_model_connections_mapping, df_model_storages_mapping], axis=0)\n",
    "df_model_object_mapping = df_model_object_mapping.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5bd925e8-09bd-4d8a-9563-39423bf0c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the investment information from the user interface into a dataframe\n",
    "df_filtered_investment_cost = filter_investment_data(name_parameter='investment_cost', **investment_cost_params)\n",
    "df_filtered_investment_limit = filter_investment_data(name_parameter='investment_limit', **investment_limit_params)\n",
    "df_filtered_existing_cap = filter_investment_data(name_parameter='capacities_exisiting', **capacities_exisiting_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e1a2fb76-9d1a-4989-8cee-8f13b1f085a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allign information of the dataframes for investments\n",
    "df_investment_cost = map_parameters_by_similarity(df_model_object_mapping, df_filtered_investment_cost)\n",
    "df_investment_limit = map_parameters_by_similarity(df_model_object_mapping, df_filtered_investment_limit)\n",
    "df_existing_cap = map_parameters_by_similarity(df_model_object_mapping, df_filtered_existing_cap)\n",
    "#move Object_name column to first column \n",
    "df_investment_limit = move_column_to_first(df_investment_limit, 'Object_name')\n",
    "df_investment_cost = move_column_to_first(df_investment_cost, 'Object_name')\n",
    "df_existing_cap = move_column_to_first(df_existing_cap, 'Object_name')\n",
    "#merge the two dataframes to have one dataframe with all the investment information from the user interface\n",
    "df_investment_params = pd.merge(df_investment_cost, df_investment_limit, on='Object_name', how='left')\n",
    "df_investment_params = pd.merge(df_investment_params, df_existing_cap, on='Object_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "582acf93-55ae-492a-ac60-bb447644e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_units = process_dataframe(df_model_units, 'Unit', 'unit')\n",
    "df_connections = process_dataframe(df_model_connections, 'Connection', 'connection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "28e86607-2ad3-4aa8-8bbd-3bee30a62970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adjust the storage loss rate values to fit to the SpineOpt implementation\n",
    "df_model_storages = adjust_frac_state_loss(df_model_storages, 'frac_state_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1f7ec120-9bbf-40af-ac29-9b429051d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the elements of the network\n",
    "df_definition, df_nodes = create_definition_dataframe(df_model_units, df_model_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f3c90d86-d62f-49aa-bf8c-a7ceec921d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jfg.eco\\Documents\\GitHub\\Nord_H2ub\\spine_projects\\01_input_data\\00_functions\\nord_h2ub_data_preparation_functions.py:388: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  unit_parameter_df = pd.concat([unit_parameter_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "C:\\Users\\jfg.eco\\Documents\\GitHub\\Nord_H2ub\\spine_projects\\01_input_data\\00_functions\\nord_h2ub_data_preparation_functions.py:388: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  unit_parameter_df = pd.concat([unit_parameter_df, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar_Plant</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steam_Plant</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>0.119292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit</td>\n",
       "      <td>min_down_time</td>\n",
       "      <td>48h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Object_name Category      Parameter     Value\n",
       "0       Solar_Plant     unit       fom_cost      1.29\n",
       "1      Electrolyzer     unit       fom_cost      4.34\n",
       "2  Methanol_Reactor     unit       fom_cost      4.45\n",
       "3       Steam_Plant     unit       fom_cost  0.119292\n",
       "4  Methanol_Reactor     unit  min_down_time       48h"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data frame for all parameters of units\n",
    "\n",
    "# Add fixed operation and maintenance cost\n",
    "unit_fom_cost_df = create_object_parameters(df_model_units, 'Unit', 'fom_cost')\n",
    "# Add unit minimal downtime\n",
    "unit_min_down_time_df = create_object_parameters(df_model_units, 'Unit', 'min_down_time')\n",
    "# Add unit on cost\n",
    "unit_on_cost_df = create_object_parameters(df_model_units, 'Unit', 'units_on_cost')\n",
    "# Add start up costs\n",
    "start_up_cost_df = create_object_parameters(df_model_units, 'Unit', 'start_up_cost')\n",
    "# Add shut down costs\n",
    "shut_down_cost_df = create_object_parameters(df_model_units, 'Unit', 'shut_down_cost')\n",
    "\n",
    "connection_fom_cost_df = create_object_parameters(df_model_connections, 'Connection', 'fom_cost')\n",
    "\n",
    "# Create a complete data frame with all parameters\n",
    "unit_parameters_df = pd.concat([unit_fom_cost_df, unit_min_down_time_df, unit_on_cost_df, start_up_cost_df, shut_down_cost_df, connection_fom_cost_df], ignore_index=True)\n",
    "\n",
    "# Show table head for control\n",
    "unit_parameters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "470215f7-7b7f-45f3-a1b6-daa11589ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame for parameters that are given as durations\n",
    "# Necessary as SpineToolbox needs a separate input to map the parameter correctly\n",
    "\n",
    "duration_parameter = 'min_down_time'\n",
    "unit_parameters_duration_df = unit_parameters_df[unit_parameters_df['Parameter'] == duration_parameter]\n",
    "# Resetting the index\n",
    "unit_parameters_duration_df = unit_parameters_duration_df.reset_index(drop=True)\n",
    "\n",
    "# Creating another DataFrame with rows that do not meet the condition\n",
    "unit_parameters_rest_df = unit_parameters_df[unit_parameters_df['Parameter'] != duration_parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1d4e42d4-76d0-480d-b7b2-bdb413adfc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the balance type of the nodes\n",
    "columns_to_select = ['Input1', 'Input2', 'Output1', 'Output2']\n",
    "df_combined = pd.concat([df_model_units, df_model_connections])\n",
    "df_combined = df_combined.reset_index(drop=True)\n",
    "\n",
    "df_nodes_network = create_connection_dataframe(df_combined, columns_to_select)\n",
    "\n",
    "# Get unique values from the 'in' column\n",
    "unique_in_values = df_nodes_network['in'].dropna().unique()\n",
    "\n",
    "# Identify values in 'in' column not present in 'out' column\n",
    "values_not_in_out = unique_in_values[~pd.Series(unique_in_values).isin(df_nodes_network['out'].dropna().unique())]\n",
    "\n",
    "# Get unique values from the 'in' column\n",
    "unique_out_values = df_nodes_network['out'].dropna().unique()\n",
    "\n",
    "# Identify values in 'in' column not present in 'out' column\n",
    "values_not_in_in = unique_out_values[~pd.Series(unique_out_values).isin(df_nodes_network['in'].dropna().unique())]\n",
    "\n",
    "# Create list of unique nodes that are either start or end nodes\n",
    "unique_nodes = values_not_in_out.tolist() + values_not_in_in.tolist()\n",
    "unique_nodes\n",
    "\n",
    "df_nodes_network.replace(np.nan, None, inplace=True)\n",
    "\n",
    "# Check for combinations that are mirrored\n",
    "mirrored_combinations = find_mirror_combinations(df_nodes_network)\n",
    "\n",
    "# Get information of connections for each node\n",
    "partners_dict1 = find_partners(df_nodes_network)\n",
    "partners_dict2 = find_partners(mirrored_combinations)\n",
    "\n",
    "# Check both lists if there are identical entries and list nodes that only have a connection to the same node\n",
    "# Storages are removed as they must be balanced\n",
    "nodes_identical = find_identical_entries(partners_dict1, partners_dict2)\n",
    "\n",
    "# Combined list of start and end nodes that should be unbalanced\n",
    "unbalanced_nodes = nodes_identical + unique_nodes\n",
    "\n",
    "df_nodes['balance_type'] = 'balance_type_node'\n",
    "df_nodes.loc[df_nodes['Object_name'].isin(unbalanced_nodes), 'balance_type'] = 'balance_type_none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0403b80a-9d3f-4557-bda6-2803650bea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add has_state_node_state_cap and frac_state_loss\n",
    "df_storages_short = df_model_storages.loc[:, ['Storage', 'has_state', 'node_state_cap', 'frac_state_loss']].rename(columns={'Storage': 'Object_name'})\n",
    "df_storages_short['has_state'] = df_storages_short['has_state'].astype(str).str.lower().replace('true', 'true')\n",
    "\n",
    "df_nodes = pd.merge(df_nodes, df_storages_short, on='Object_name', how='left')\n",
    "df_nodes['demand'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bb44a55f-bd0d-41f3-a96a-2fc67ae92a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_name</th>\n",
       "      <th>Category</th>\n",
       "      <th>balance_type</th>\n",
       "      <th>has_state</th>\n",
       "      <th>node_state_cap</th>\n",
       "      <th>frac_state_loss</th>\n",
       "      <th>demand</th>\n",
       "      <th>node_slack_penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Water</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Power_Kasso</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaporized_Carbon_Dioxide</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hydrogen_storage_Kasso</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>true</td>\n",
       "      <td>5478.676451</td>\n",
       "      <td>0.043264</td>\n",
       "      <td></td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carbon_Dioxide</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Object_name Category       balance_type has_state  \\\n",
       "0                     Water     node  balance_type_none       NaN   \n",
       "1               Power_Kasso     node  balance_type_node       NaN   \n",
       "2  Vaporized_Carbon_Dioxide     node  balance_type_node       NaN   \n",
       "3    Hydrogen_storage_Kasso     node  balance_type_node      true   \n",
       "4            Carbon_Dioxide     node  balance_type_none       NaN   \n",
       "\n",
       "   node_state_cap  frac_state_loss demand node_slack_penalty  \n",
       "0             NaN              NaN                            \n",
       "1             NaN              NaN                   1000000  \n",
       "2             NaN              NaN                   1000000  \n",
       "3     5478.676451         0.043264                   1000000  \n",
       "4             NaN              NaN                            "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe with all nodes that should have a slack based on the unit input and outputs\n",
    "nodes_for_slack_df = check_entries_exist(df_model_units, 'node')\n",
    "# Merge the information into the prepared data frame\n",
    "merged_df = pd.merge(df_nodes, nodes_for_slack_df, left_on='Object_name', right_on='node', how='left')\n",
    "merged_df = merged_df.drop(columns=['node'])\n",
    "merged_df['node_slack_penalty'] = merged_df['node_slack_penalty'].replace({True: 1000000, False: ''})\n",
    "# Create a dataframe with all nodes that should have a slack based on the connection input and outputs\n",
    "nodes_for_slack_df2 = check_entries_exist(df_model_connections, 'connection')\n",
    "# Merge the information into the prepared data frame\n",
    "merged_df2 = pd.merge(df_nodes, nodes_for_slack_df2, left_on='Object_name', right_on='connection', how='left')\n",
    "merged_df2 = merged_df2.drop(columns=['connection'])\n",
    "merged_df2['node_slack_penalty'] = merged_df2['node_slack_penalty'].replace({True: 1000000, False: ''})\n",
    "# Link the information about the slack of both data frames\n",
    "merged_df2['node_slack_penalty'] = merged_df['node_slack_penalty'].combine_first(merged_df2['node_slack_penalty'])\n",
    "# Clean the information that only nodes with 'balance_type_node' have a penalty\n",
    "merged_df2.loc[merged_df2['balance_type'] == 'balance_type_none', 'node_slack_penalty'] = ''\n",
    "\n",
    "# Add the information into the df_nodes\n",
    "df_nodes['node_slack_penalty'] = merged_df2['node_slack_penalty']\n",
    "\n",
    "# Show table head for control\n",
    "df_nodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f3dc6-ea13-486b-9860-6bd41f57b3a7",
   "metadata": {},
   "source": [
    "#### Times series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e60a7947-9d7f-480f-847a-f22419719660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust renewables columns names\n",
    "df_PV_availabilityfactors_values.rename(columns={'time': 'time [UTC]', \n",
    "                                                 'local_time': 'time [' + area + ']',\n",
    "                                                 'electricity': 'unit_availability_factor'}, inplace=True)\n",
    "df_wind_availabilityfactors_values.rename(columns={'time': 'time [UTC]',\n",
    "                                                   'local_time': 'time [' + area + ']',\n",
    "                                                   'electricity_onshore': 'unit_availability_factor_onshore',\n",
    "                                                   'electricity_offshore': 'unit_availability_factor_offshore'}, inplace=True)\n",
    "# Adjust power prices\n",
    "df_powerprices_values.rename(columns={'HourUTC': 'time [UTC]', \n",
    "                                         'HourDK': 'time [' + area + ']'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b3c37-228f-47f0-a99e-2df1f87512d5",
   "metadata": {},
   "source": [
    "## Fitting data into format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b527344-851f-47c0-a12e-72942d4176eb",
   "metadata": {},
   "source": [
    "### Relationships:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea16b2-0e98-4ca2-b6ec-aa840ac09d20",
   "metadata": {},
   "source": [
    "#### Object__from/to_node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2a4c5f93-8fa4-4d88-83f9-767f83ff7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNITS ###\n",
    "df_unit_relation_parameter_data = pd.DataFrame(object_relationship_unit_nodes(df_model_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "74ae88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional electricity connections if not already existent\n",
    "\n",
    "units = df_units.iloc[:, 0].tolist()\n",
    "length = len(units)\n",
    "data = {\n",
    "    \"Relationship_class_name\": [\"unit__from_node\"] * length,\n",
    "    \"Object_class\": [\"unit\"] * length,\n",
    "    \"Object_name\": units,\n",
    "    \"Node\": [\"Power_Kasso\"] * length\n",
    "}\n",
    "df_electricity = pd.DataFrame(data)\n",
    "\n",
    "units_with_from_node = df_unit_relation_parameter_data[df_unit_relation_parameter_data['Relationship_class_name'].str.contains('unit__from_node')]\n",
    "valid_object_names = units_with_from_node['Object_name']\n",
    "df_electricity_filtered = df_electricity[df_electricity['Object_name'].isin(valid_object_names)]\n",
    "\n",
    "merged_df = pd.merge(df_electricity_filtered, units_with_from_node, on=['Relationship_class_name', 'Object_class', 'Object_name', 'Node'], how='left', indicator=True)\n",
    "df_electricity_nodes = merged_df[merged_df['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "df_unit_relation_parameter_data = pd.concat([df_unit_relation_parameter_data, df_electricity_nodes], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e92030e0-f252-49f5-b58c-defa9a0da163",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONNECTIONS ###\n",
    "df_connection_relation_parameter_data = object_relationship_connection_nodes(df_model_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "65d8c41c-8fb4-4a60-883b-94b70f5ace80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relationship_class_name</th>\n",
       "      <th>Object_class</th>\n",
       "      <th>Object_name</th>\n",
       "      <th>Node</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unit__to_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Solar_Plant</td>\n",
       "      <td>Power_Kasso</td>\n",
       "      <td>unit_capacity</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unit__from_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>Power_Kasso</td>\n",
       "      <td>unit_capacity</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unit__from_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>Power_Kasso</td>\n",
       "      <td>minimum_operating_point</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unit__to_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>Hydrogen_Kasso</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unit__from_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>Water</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Relationship_class_name Object_class   Object_name            Node  \\\n",
       "0           unit__to_node         unit   Solar_Plant     Power_Kasso   \n",
       "1         unit__from_node         unit  Electrolyzer     Power_Kasso   \n",
       "2         unit__from_node         unit  Electrolyzer     Power_Kasso   \n",
       "3           unit__to_node         unit  Electrolyzer  Hydrogen_Kasso   \n",
       "4         unit__from_node         unit  Electrolyzer           Water   \n",
       "\n",
       "                 Parameter  Value  \n",
       "0            unit_capacity  100.0  \n",
       "1            unit_capacity   30.0  \n",
       "2  minimum_operating_point   0.02  \n",
       "3                                  \n",
       "4                                  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create combined DataFrame:\n",
    "df_object__node = pd.concat([df_unit_relation_parameter_data, df_connection_relation_parameter_data])\n",
    "df_object__node = df_object__node.reset_index(drop=True)\n",
    "\n",
    "# Show df head for control\n",
    "df_object__node.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "36e1391f-d8cd-45dd-9867-7aefa0327740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relationship_class_name</th>\n",
       "      <th>Object_class</th>\n",
       "      <th>Object_name</th>\n",
       "      <th>Node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unit__to_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Solar_Plant</td>\n",
       "      <td>Power_Kasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unit__from_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>Power_Kasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unit__to_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>Hydrogen_Kasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unit__from_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unit__to_node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>Waste_Heat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Relationship_class_name Object_class   Object_name            Node\n",
       "0           unit__to_node         unit   Solar_Plant     Power_Kasso\n",
       "1         unit__from_node         unit  Electrolyzer     Power_Kasso\n",
       "2           unit__to_node         unit  Electrolyzer  Hydrogen_Kasso\n",
       "3         unit__from_node         unit  Electrolyzer           Water\n",
       "4           unit__to_node         unit  Electrolyzer      Waste_Heat"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the definition of the object_node relationships\n",
    "df_object__node_definitions = pd.DataFrame(df_object__node[['Relationship_class_name', 'Object_class', 'Object_name', 'Node']])\n",
    "df_object__node_definitions = df_object__node_definitions.drop_duplicates()\n",
    "df_object__node_definitions = df_object__node_definitions.reset_index(drop=True)\n",
    "\n",
    "# To avoid import errors the connections  will be removed from the definitions df\n",
    "# Dropping rows where 'Object_class' is 'connection'\n",
    "df_object__node_definitions  = df_object__node_definitions [df_object__node_definitions ['Object_class'] != 'connection']\n",
    "\n",
    "# Drop rows where no parameters for the relationship are defined (column has missing values (NaN or None))\n",
    "drop_no_value_column = 'Parameter'\n",
    "df_object__node_values = df_object__node[df_object__node[drop_no_value_column] != '']\n",
    "\n",
    "# Show df head for control\n",
    "df_object__node_definitions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebeb807-b807-4882-b8cd-67a174c8edbd",
   "metadata": {},
   "source": [
    "#### Object__node_node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1fd5a160-3f18-4656-82ee-484e7e703cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Object_class</th>\n",
       "      <th>Object_name</th>\n",
       "      <th>Node1</th>\n",
       "      <th>Node2</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unit__node__node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>Power_Kasso</td>\n",
       "      <td>Water</td>\n",
       "      <td>fix_ratio_in_in_unit_flow</td>\n",
       "      <td>0.005850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unit__node__node</td>\n",
       "      <td>unit</td>\n",
       "      <td>CO2_Vaporizer</td>\n",
       "      <td>Power_Kasso</td>\n",
       "      <td>Carbon_Dioxide</td>\n",
       "      <td>fix_ratio_in_in_unit_flow</td>\n",
       "      <td>0.003601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unit__node__node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Destilation_Tower</td>\n",
       "      <td>Raw_Methanol</td>\n",
       "      <td>Steam</td>\n",
       "      <td>fix_ratio_in_in_unit_flow</td>\n",
       "      <td>17.277902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unit__node__node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>Hydrogen_Kasso</td>\n",
       "      <td>Vaporized_Carbon_Dioxide</td>\n",
       "      <td>fix_ratio_in_in_unit_flow</td>\n",
       "      <td>5.173497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unit__node__node</td>\n",
       "      <td>unit</td>\n",
       "      <td>Steam_Plant</td>\n",
       "      <td>Power_Kasso</td>\n",
       "      <td>Water</td>\n",
       "      <td>fix_ratio_in_in_unit_flow</td>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Relationship Object_class        Object_name           Node1  \\\n",
       "0  unit__node__node         unit       Electrolyzer     Power_Kasso   \n",
       "1  unit__node__node         unit      CO2_Vaporizer     Power_Kasso   \n",
       "2  unit__node__node         unit  Destilation_Tower    Raw_Methanol   \n",
       "3  unit__node__node         unit   Methanol_Reactor  Hydrogen_Kasso   \n",
       "4  unit__node__node         unit        Steam_Plant     Power_Kasso   \n",
       "\n",
       "                      Node2                  Parameter      Value  \n",
       "0                     Water  fix_ratio_in_in_unit_flow   0.005850  \n",
       "1            Carbon_Dioxide  fix_ratio_in_in_unit_flow   0.003601  \n",
       "2                     Steam  fix_ratio_in_in_unit_flow  17.277902  \n",
       "3  Vaporized_Carbon_Dioxide  fix_ratio_in_in_unit_flow   5.173497  \n",
       "4                     Water  fix_ratio_in_in_unit_flow   0.000724  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define which columns to check\n",
    "columns_In_In_Unit = ['Unit', 'Input1', 'Input2']\n",
    "columns_In_Out_Unit = ['Unit', 'Input1', 'Output1']\n",
    "columns_Out_Out_Unit = ['Unit', 'Output1', 'Output2']\n",
    "columns_In_In_Connection = ['Connection', 'Input1', 'Input2']\n",
    "columns_In_Out_Connection = ['Connection', 'Input1', 'Output1']\n",
    "columns_Out_Out_Connection = ['Connection', 'Output1', 'Output2']\n",
    "columns_Out_In_Connection = ['Connection', 'Output1', 'Input1']\n",
    "\n",
    "### UNITS ###\n",
    "# Create list of tuples with values of cells + fix_ratio_XXX_XXX\n",
    "values_in_in_units = [('unit__node__node', 'unit', row[columns_In_In_Unit[0]], row[columns_In_In_Unit[1]], row[columns_In_In_Unit[2]], \n",
    "                       'fix_ratio_in_in_unit_flow', row['Relation_In_In']) \n",
    "                      if not pd.isnull(row[columns_In_In_Unit]).any() else (np.nan, np.nan, None) for _, row in df_model_units.iterrows() \n",
    "                      if not pd.isnull(row[columns_In_In_Unit]).any()]\n",
    "values_in_out_units = [('unit__node__node', 'unit', row[columns_In_Out_Unit[0]], row[columns_In_Out_Unit[1]], row[columns_In_Out_Unit[2]], \n",
    "                        'fix_ratio_in_out_unit_flow', row['Relation_In_Out']) \n",
    "                      if not pd.isnull(row[columns_In_Out_Unit]).any() else (np.nan, np.nan, None) for _, row in df_model_units.iterrows() \n",
    "                      if not pd.isnull(row[columns_In_Out_Unit]).any()]\n",
    "values_out_out_units = [('unit__node__node', 'unit', row[columns_Out_Out_Unit[0]], row[columns_Out_Out_Unit[1]], row[columns_Out_Out_Unit[2]], \n",
    "                         'fix_ratio_out_out_unit_flow', row['Relation_Out_Out']) \n",
    "                      if not pd.isnull(row[columns_Out_Out_Unit]).any() else (np.nan, np.nan, None) for _, row in df_model_units.iterrows() \n",
    "                      if not pd.isnull(row[columns_Out_Out_Unit]).any()]\n",
    "\n",
    "df_fix_ratio_in_in_units = pd.DataFrame(values_in_in_units, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                     'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_in_out_units = pd.DataFrame(values_in_out_units, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                       'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_out_out_units = pd.DataFrame(values_out_out_units, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                         'Node2', 'Parameter', 'Value'])\n",
    "\n",
    "### CONNECTIONS ###\n",
    "values_in_in_connections = [('connection__node__node', 'connection', row[columns_In_In_Connection[0]], \n",
    "                             row[columns_In_In_Connection[1]], row[columns_In_In_Connection[2]], \n",
    "                             'fix_ratio_in_in_connection_flow', row['Relation_In_In']) \n",
    "                            if not pd.isnull(row[columns_In_In_Connection]).any() else (np.nan, np.nan, None) for _, row in df_model_connections.iterrows() \n",
    "                            if not pd.isnull(row[columns_In_In_Connection]).any()]\n",
    "# Comment: connections_in_out are no longer supported by Spine, therefore the values get inverted\n",
    "values_in_out_connections_inverted = [('connection__node__node', 'connection', row[columns_In_Out_Connection[0]], \n",
    "                              row[columns_In_Out_Connection[1]], row[columns_In_Out_Connection[2]], \n",
    "                              'fix_ratio_out_in_connection_flow', 1/row['Relation_In_Out']) \n",
    "                             if not pd.isnull(row[columns_In_Out_Connection]).any() else (np.nan, np.nan, None) for _, row in df_model_connections.iterrows() \n",
    "                             if not pd.isnull(row[columns_In_Out_Connection]).any()]\n",
    "values_out_out_connections = [('connection__node__node', 'connection', row[columns_Out_Out_Connection[0]], \n",
    "                               row[columns_Out_Out_Connection[1]], row[columns_Out_Out_Connection[2]], \n",
    "                               'fix_ratio_out_out_connection_flow', row['Relation_Out_Out']) \n",
    "                              if not pd.isnull(row[columns_Out_Out_Connection]).any() else (np.nan, np.nan, None) for _, row in df_model_connections.iterrows() \n",
    "                              if not pd.isnull(row[columns_Out_Out_Connection]).any()]\n",
    "values_out_in_connections = [('connection__node__node', 'connection', row[columns_Out_In_Connection[0]], \n",
    "                               row[columns_Out_In_Connection[1]], row[columns_Out_In_Connection[2]], \n",
    "                               'fix_ratio_out_in_connection_flow', row['Relation_Out_In']) \n",
    "                              if not pd.isnull(row[columns_Out_In_Connection]).any() else (np.nan, np.nan, None) for _, row in df_model_connections.iterrows() \n",
    "                              if not pd.isnull(row[columns_Out_In_Connection]).any()]\n",
    "\n",
    "df_fix_ratio_in_in_connections = pd.DataFrame(values_in_in_connections, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                                 'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_in_out_connections = pd.DataFrame(values_in_out_connections_inverted, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                                   'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_out_out_connections = pd.DataFrame(values_out_out_connections, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                                     'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_out_in_connections = pd.DataFrame(values_out_in_connections, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                                     'Node2', 'Parameter', 'Value'])\n",
    "\n",
    "# Create Object_node_node\n",
    "df_object_node_node = pd.concat([df_fix_ratio_in_in_units, df_fix_ratio_in_out_units, df_fix_ratio_out_out_units, \n",
    "                                df_fix_ratio_in_in_connections, df_fix_ratio_in_out_connections, \n",
    "                                df_fix_ratio_out_out_connections, df_fix_ratio_out_in_connections])\n",
    "df_object_node_node = df_object_node_node.reset_index(drop=True)\n",
    "\n",
    "df_object_node_node = df_object_node_node.dropna(subset=['Value'])\n",
    "\n",
    "# Show table head for control\n",
    "df_object_node_node.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1388dfc3-fb27-4571-ba84-8593ea8413df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For storages, the out_in_connetion is set in both directions\n",
    "\n",
    "# Step 1: Check if the 'Object_name' column contains the word 'storage'\n",
    "storage_condition = df_object_node_node['Object_name'].str.contains('storage', case=False)\n",
    "\n",
    "# Step 2: Check if the 'Parameter' column starts with 'fix_ratio_'\n",
    "parameter_condition = df_object_node_node['Parameter'].str.startswith('fix_ratio_')\n",
    "\n",
    "# Step 3: Combine both conditions\n",
    "combined_condition = storage_condition & parameter_condition\n",
    "\n",
    "# Step 2: Update the 'Parameter' column for rows that meet the condition\n",
    "df_object_node_node.loc[storage_condition, 'Parameter'] = 'fix_ratio_out_in_connection_flow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "68543d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if second node is necessary for demand\n",
    "for index, row in df_model_units.iterrows():\n",
    "    df_definition, df_nodes, df_connections, df_object__node_values, df_object_node_node = check_demand_node(\n",
    "        row, temporal_block, resolution_to_block, df_definition, \n",
    "        df_nodes, df_connections, df_object__node_values, \n",
    "        df_object_node_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3870c8f",
   "metadata": {},
   "source": [
    "#### Hard-coded parameter for destillation tower (please remove once better solution is found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f39b3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Relationship\": [\"unit__node__node\"],\n",
    "    \"Object_class\": \"unit\",\n",
    "    \"Object_name\": \"Destilation_Tower\",\n",
    "    \"Node1\": \"Power_Kasso\",\n",
    "    \"Node2\": \"E-Methanol_Kasso\",\n",
    "    \"Parameter\": \"max_ratio_in_out_unit_flow\",\n",
    "    \"Value\": 0.000001\n",
    "}\n",
    "df_hardcode_destillation = pd.DataFrame(data)\n",
    "\n",
    "# Append new rows to the original DataFrame\n",
    "df_object_node_node = pd.concat([df_object_node_node, df_hardcode_destillation], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d2046",
   "metadata": {},
   "source": [
    "#### Investments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8d0cccc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jfg.eco\\AppData\\Local\\Temp\\ipykernel_24248\\1821009392.py:74: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_units_inv_parameters = pd.concat([df_units_inv_parameters, pd.DataFrame(rows_to_add)], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_name</th>\n",
       "      <th>unit_investment_variable_type</th>\n",
       "      <th>initial_units_invested_available</th>\n",
       "      <th>number_of_units</th>\n",
       "      <th>candidate_units</th>\n",
       "      <th>unit_investment_cost</th>\n",
       "      <th>unit_investment_tech_lifetime</th>\n",
       "      <th>unit_investment_econ_lifetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar_Plant</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.595616e+06</td>\n",
       "      <td>12775D</td>\n",
       "      <td>12775D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.273753e+06</td>\n",
       "      <td>9125D</td>\n",
       "      <td>9125D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO2_Vaporizer</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.493151e+06</td>\n",
       "      <td>7300D</td>\n",
       "      <td>7300D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Destilation_Tower</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333589e+06</td>\n",
       "      <td>10950D</td>\n",
       "      <td>10950D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333589e+06</td>\n",
       "      <td>10950D</td>\n",
       "      <td>10950D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Object_name             unit_investment_variable_type  \\\n",
       "0        Solar_Plant  unit_investment_variable_type_continuous   \n",
       "1       Electrolyzer  unit_investment_variable_type_continuous   \n",
       "2      CO2_Vaporizer  unit_investment_variable_type_continuous   \n",
       "3  Destilation_Tower  unit_investment_variable_type_continuous   \n",
       "4   Methanol_Reactor  unit_investment_variable_type_continuous   \n",
       "\n",
       "  initial_units_invested_available number_of_units candidate_units  \\\n",
       "0                                0               0               1   \n",
       "1                                0               0               1   \n",
       "2                                0               0               1   \n",
       "3                                0               0               1   \n",
       "4                                0               0               1   \n",
       "\n",
       "   unit_investment_cost unit_investment_tech_lifetime  \\\n",
       "0          1.595616e+06                        12775D   \n",
       "1          2.273753e+06                         9125D   \n",
       "2          2.493151e+06                         7300D   \n",
       "3          2.333589e+06                        10950D   \n",
       "4          2.333589e+06                        10950D   \n",
       "\n",
       "  unit_investment_econ_lifetime  \n",
       "0                        12775D  \n",
       "1                         9125D  \n",
       "2                         7300D  \n",
       "3                        10950D  \n",
       "4                        10950D  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize df\n",
    "'''TODO: Find a way to work with the existing capacity as share in the number of units but regarding the new\n",
    "way of using a investment limit (there must be a change regarding the current implementation. \n",
    "In this case, the unit_capacity must be changed to the investment_limit.'''\n",
    "\n",
    "df_units_inv_parameters = pd.DataFrame(columns=['Object_name', 'unit_investment_variable_type', \n",
    "                                                    'initial_units_invested_available', 'number_of_units', \n",
    "                                                    'candidate_units', 'unit_investment_cost', \n",
    "                                                    'unit_investment_tech_lifetime', 'unit_investment_econ_lifetime'])\n",
    "\n",
    "# Choose correct column for investment costs based on chosen year\n",
    "year_columns = {int(col.split()[-1]): col for col in df_investment_costs_raw.columns if 'Value' in col}\n",
    "closest_year = min(year_columns.keys(), key=lambda x: abs(x - year))\n",
    "selected_column = year_columns[closest_year]\n",
    "\n",
    "# Add values if investment is selected\n",
    "if candidate_nonzero:\n",
    "    rows_to_add = []\n",
    "    \n",
    "    for index, row in df_model_units_raw.iterrows():\n",
    "        object_type = row['Object_type']\n",
    "        \n",
    "        cap_input = row['Cap_Input1_existing'] if not pd.isna(row['Cap_Input1_existing']) else 0\n",
    "        cap_output = row['Cap_Output1_existing'] if not pd.isna(row['Cap_Output1_existing']) else 0\n",
    "        \n",
    "        # Default investment cost\n",
    "        matching_row = df_investment_costs_raw[df_investment_costs_raw['Object_type'] == object_type]\n",
    "        if not matching_row.empty:\n",
    "            # Extract the investment cost and lifetime from matching_row\n",
    "            investment_cost = matching_row[selected_column].values[0]\n",
    "            lifetime_str = matching_row['Lifetime'].values[0]\n",
    "            \n",
    "            # Convert the lifetime to days\n",
    "            lifetime = convert_to_days(lifetime_str, year)\n",
    "        else:\n",
    "            investment_cost = 0  # Default investment cost if no match is found\n",
    "            lifetime = '10950D'  # Default lifetime if no match is found\n",
    "        default_value = investment_cost * (cap_input + cap_output)\n",
    "        \n",
    "        # Externally chosen investment cost\n",
    "        pattern = re.compile(rf\"inv_cost_.*{object_type}\")\n",
    "        matching_vars = [var for var in globals() if pattern.match(var)]\n",
    "        \n",
    "        if matching_vars:\n",
    "            variable_name = matching_vars[0]\n",
    "            variable_value = globals()[variable_name]\n",
    "            \n",
    "            if variable_value is not None:\n",
    "                special_value = variable_value * (cap_input + cap_output)\n",
    "                unit_investment_cost = special_value\n",
    "            else:\n",
    "                unit_investment_cost = default_value\n",
    "        else:\n",
    "            # If no external costs, use the default cost\n",
    "            unit_investment_cost = default_value\n",
    "        \n",
    "        # Add the results for this row to df_units_inv_parameters\n",
    "        row_to_add = {'Object_name': row['Unit'],\n",
    "            'unit_investment_variable_type': 'unit_investment_variable_type_continuous',\n",
    "            'initial_units_invested_available': 0,\n",
    "            'number_of_units': row['number_of_units'],\n",
    "            #new way, when using exisiting capacities\n",
    "            #'number_of_units': EXISITING / LIMIT,\n",
    "            'candidate_units': 1,\n",
    "            'unit_investment_cost': unit_investment_cost,\n",
    "            #new way, when using exisiting capacities\n",
    "            #'unit_investment_cost': LIMIT * INV_COST_MW,\n",
    "            'unit_investment_tech_lifetime': lifetime,\n",
    "            'unit_investment_econ_lifetime': lifetime  # Same as tech lifetime\n",
    "        }\n",
    "        \n",
    "        rows_to_add.append(row_to_add)\n",
    "        \n",
    "    df_units_inv_parameters = pd.concat([df_units_inv_parameters, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
    "    \n",
    "    # Scale investment costs to lifetime\n",
    "    df_units_inv_parameters = scale_costs(df_units_inv_parameters, start_date, end_date, 'unit')\n",
    "    \n",
    "# Show table head for control\n",
    "df_units_inv_parameters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8e8b7f66-79be-423f-9413-7142c4ac5da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_name</th>\n",
       "      <th>unit_investment_variable_type</th>\n",
       "      <th>initial_units_invested_available</th>\n",
       "      <th>number_of_units</th>\n",
       "      <th>candidate_units</th>\n",
       "      <th>unit_investment_cost</th>\n",
       "      <th>unit_investment_tech_lifetime</th>\n",
       "      <th>unit_investment_econ_lifetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar_Plant</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.595616e+06</td>\n",
       "      <td>12775D</td>\n",
       "      <td>12775D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.273753e+06</td>\n",
       "      <td>9125D</td>\n",
       "      <td>9125D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO2_Vaporizer</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.493151e+06</td>\n",
       "      <td>7300D</td>\n",
       "      <td>7300D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Destilation_Tower</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333589e+06</td>\n",
       "      <td>10950D</td>\n",
       "      <td>10950D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333589e+06</td>\n",
       "      <td>10950D</td>\n",
       "      <td>10950D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Steam_Plant</td>\n",
       "      <td>unit_investment_variable_type_continuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.479452e+05</td>\n",
       "      <td>7300D</td>\n",
       "      <td>7300D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Object_name             unit_investment_variable_type  \\\n",
       "0        Solar_Plant  unit_investment_variable_type_continuous   \n",
       "1       Electrolyzer  unit_investment_variable_type_continuous   \n",
       "2      CO2_Vaporizer  unit_investment_variable_type_continuous   \n",
       "3  Destilation_Tower  unit_investment_variable_type_continuous   \n",
       "4   Methanol_Reactor  unit_investment_variable_type_continuous   \n",
       "5        Steam_Plant  unit_investment_variable_type_continuous   \n",
       "\n",
       "  initial_units_invested_available number_of_units candidate_units  \\\n",
       "0                                0               1               1   \n",
       "1                                0               0               1   \n",
       "2                                0               0               1   \n",
       "3                                0               0               1   \n",
       "4                                0               0               1   \n",
       "5                                0               0               1   \n",
       "\n",
       "   unit_investment_cost unit_investment_tech_lifetime  \\\n",
       "0          1.595616e+06                        12775D   \n",
       "1          2.273753e+06                         9125D   \n",
       "2          2.493151e+06                         7300D   \n",
       "3          2.333589e+06                        10950D   \n",
       "4          2.333589e+06                        10950D   \n",
       "5          7.479452e+05                         7300D   \n",
       "\n",
       "  unit_investment_econ_lifetime  \n",
       "0                        12775D  \n",
       "1                         9125D  \n",
       "2                         7300D  \n",
       "3                        10950D  \n",
       "4                        10950D  \n",
       "5                         7300D  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to filter the investment parameters for later use\n",
    "#this must be improved to integrate all RES into the dataframe not just solar\n",
    "df_units_inv_parameters_test = update_units_inv_parameters(df_units_inv_parameters, ['Solar_Plant'], candidate_nonzero)\n",
    "df_units_inv_parameters_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0faec4c8-2b61-45be-b36a-ce83b06a6f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_name</th>\n",
       "      <th>investment_cost</th>\n",
       "      <th>investment_limit</th>\n",
       "      <th>capacities_exisiting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hydrogen_storage_Kasso</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-Methanol_storage_Kasso</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steam_Plant</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Object_name  investment_cost  investment_limit  \\\n",
       "0              Electrolyzer            100.0               NaN   \n",
       "1    Hydrogen_storage_Kasso            100.0               NaN   \n",
       "2          Methanol_Reactor            100.0               NaN   \n",
       "3  E-Methanol_storage_Kasso             10.0               NaN   \n",
       "4               Steam_Plant            100.0               NaN   \n",
       "\n",
       "   capacities_exisiting  \n",
       "0                  30.0  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_investment_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9dbee8-1be3-45d1-9d24-0b6d6c15619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing\n",
    "df_investment_params['investment_limit'] = 10\n",
    "#relevant for later operation\n",
    "df_investment_params['investment_cost_total'] = df_investment_params['investment_limit']*df_investment_params['investment_cost']\n",
    "df_investment_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc88a35-ee4c-4dc5-bdcc-702835aa32d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust the investment values in case there are values defined by the user request\n",
    "#necessary to change the number_of_units in case of defined existing capacities\n",
    "#necessary to adjust the unit_capacity in case of new investment limit\n",
    "#necessary to change the unit_investment_cost in case of new investment limit\n",
    "\n",
    "\n",
    "#changes in the df_units_inv_parameters for number_of_units and unit_investment_cost\n",
    "df_units_inv_parameters\n",
    "\n",
    "#changes in the df_object__node of the unit_capacity\n",
    "#relevant to change the investment cells to a later point in the notebook\n",
    "df_object__node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize df\n",
    "df_connections_inv_parameters = pd.DataFrame(columns=['Object_name', 'Parameter_name',\n",
    "                                                      'Connection_type', 'connection_investment_variable_type',\n",
    "                                                      'initial_connections_invested_available', 'number_of_connections',\n",
    "                                                      'candidate_connections', 'connection_investment_cost',\n",
    "                                                      'connection_investment_tech_lifetime', 'connection_investment_econ_lifetime'])\n",
    "\n",
    "# Add values if investment is selected\n",
    "if candidate_nonzero:\n",
    "    rows_to_add = []\n",
    "    \n",
    "    for index, row in df_model_connections_raw.iterrows():\n",
    "        object_type = row['Object_type']\n",
    "        \n",
    "        matching_row = df_investment_costs_raw[df_investment_costs_raw['Object_type'] == object_type]\n",
    "        if not matching_row.empty:\n",
    "            # Extract the investment cost and lifetime from matching_row\n",
    "            investment_cost_default = matching_row[selected_column].values[0]\n",
    "        else:\n",
    "            investment_cost_default = 0  # Default investment cost if no match is found\n",
    "        \n",
    "        # Scale default costs up with meters\n",
    "        \n",
    "        connection_type = row['Connection_type']\n",
    "        lifetime = row['connection_investment_tech_lifetime']\n",
    "        lifetime_str = row['connection_investment_tech_lifetime']\n",
    "        # Convert the lifetime to days\n",
    "        lifetime = convert_to_days(lifetime_str, year)\n",
    "        \n",
    "        # Add the results for this row to df_units_inv_parameters\n",
    "        row_to_add = {'Object_name': row['Connection'],\n",
    "                      'Parameter_name': 'connection_type',\n",
    "                      'Connection_type': connection_type,\n",
    "                      'connection_investment_variable_type': 'connection_investment_variable_type_continuous',\n",
    "                      'initial_connections_invested_available': 0,\n",
    "                      'number_of_connections': row['number_of_connections'],\n",
    "                      'candidate_connections': 1,\n",
    "                      'connection_investment_cost': investment_cost_default,\n",
    "                      'connection_investment_tech_lifetime': lifetime,\n",
    "                      'connection_investment_econ_lifetime': lifetime  # Same as tech lifetime\n",
    "        }\n",
    "        \n",
    "        rows_to_add.append(row_to_add)\n",
    "        \n",
    "    df_connections_inv_parameters = pd.concat([df_connections_inv_parameters, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
    "    \n",
    "    # Scale investment costs to lifetime\n",
    "    df_connections_inv_parameters = scale_costs(df_connections_inv_parameters, start_date, end_date, 'connection')\n",
    "    \n",
    "# Show table head for control\n",
    "df_connections_inv_parameters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a188ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize df\n",
    "df_storages_inv_parameters = pd.DataFrame(columns=['Object_name', 'storage_investment_variable_type',\n",
    "                                                       'initial_storages_invested', 'number_of_storages',\n",
    "                                                       'candidate_storages', 'storage_investment_cost',\n",
    "                                                       'storage_investment_tech_lifetime', 'storage_investment_econ_lifetime'])\n",
    "\n",
    "# Add values if investment is selected\n",
    "if candidate_nonzero:\n",
    "    rows_to_add = []\n",
    "    \n",
    "    for index, row in df_model_storages_raw.iterrows():\n",
    "        object_type = row['Object_type']\n",
    "        \n",
    "        node_value = row['node_state_cap'] if not pd.isna(row['node_state_cap']) else 0\n",
    "        \n",
    "        # Default investment cost\n",
    "        matching_row = df_investment_costs_raw[df_investment_costs_raw['Object_type'] == object_type]\n",
    "        if not matching_row.empty:\n",
    "            # Extract the investment cost and lifetime from matching_row\n",
    "            investment_cost = matching_row[selected_column].values[0]\n",
    "            lifetime_str = matching_row['Lifetime'].values[0]\n",
    "            # Convert the lifetime to days\n",
    "            lifetime = convert_to_days(lifetime_str, year)\n",
    "            \n",
    "        else:\n",
    "            investment_cost = 0  # Default investment cost if no match is found\n",
    "            lifetime = '10950D'  # Default lifetime if no match is found\n",
    "        \n",
    "        default_value = investment_cost * node_value\n",
    "        \n",
    "        # Externally chosen investment cost\n",
    "        pattern = re.compile(rf\"inv_cost_.*{object_type}\")\n",
    "        matching_vars = [var for var in globals() if pattern.match(var)]\n",
    "        \n",
    "        if matching_vars:\n",
    "            variable_name = matching_vars[0]\n",
    "            variable_value = globals()[variable_name]\n",
    "            \n",
    "            if variable_value is not None:\n",
    "                special_value = variable_value * node_value\n",
    "                storage_investment_cost = special_value\n",
    "            else:\n",
    "                storage_investment_cost = default_value\n",
    "        else:\n",
    "            # If no matching variable, use the default calculation\n",
    "            storage_investment_cost = default_value\n",
    "        \n",
    "        # Add the results for this row to df_units_inv_parameters\n",
    "        row_to_add = {'Object_name': row['Storage'],\n",
    "            'storage_investment_variable_type': 'storage_investment_variable_type_continuous',\n",
    "            'initial_storages_invested': 0,\n",
    "            'number_of_storages': row['number_of_storages'],\n",
    "            'candidate_storages': 1,\n",
    "            'storage_investment_cost': storage_investment_cost,\n",
    "            'storage_investment_tech_lifetime': lifetime,\n",
    "            'storage_investment_econ_lifetime': lifetime  # Same as tech lifetime\n",
    "        }\n",
    "        \n",
    "        rows_to_add.append(row_to_add)\n",
    "        \n",
    "    df_storages_inv_parameters = pd.concat([df_storages_inv_parameters, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
    "    \n",
    "    # Scale investment costs to lifetime\n",
    "    df_storages_inv_parameters = scale_costs(df_storages_inv_parameters, start_date, end_date, 'storage')\n",
    "    \n",
    "# Add to df_nodes table\n",
    "df_nodes = pd.merge(df_nodes, df_storages_inv_parameters, on = 'Object_name', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55192bdb",
   "metadata": {},
   "source": [
    "### Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b971c4",
   "metadata": {},
   "source": [
    "#### Model relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf465d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing definition of model components\n",
    "column_names_model_components = {'Object_class_name':['model','temporal_block','stochastic_scenario', 'stochastic_structure', 'report'],\n",
    "                      'Object_name': [model_name, temporal_block, stochastic_scenario, stochastic_structure, report_name]}\n",
    "df_model_components = pd.DataFrame(column_names_model_components, index=None)\n",
    "\n",
    "# Adding a default investment temporal block if investment = true \n",
    "if candidate_nonzero:\n",
    "    df_model_components.loc[len(df_model_components.index)] = ['temporal_block', 'Default_Investment_period']\n",
    "\n",
    "# Outputs:\n",
    "reports_list = list(reports)\n",
    "df_outputs = pd.DataFrame({\n",
    "    'Object_class_name': ['output']*len(reports_list),\n",
    "    'Object_name': reports_list\n",
    "})\n",
    "df_model_components = pd.concat([df_model_components, df_outputs], axis=0)\n",
    "df_model_components = df_model_components.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add reports chosen in main\n",
    "column_names_model_structure = {'Object_class_name':['model','temporal_block','stochastic_scenario', 'stochastic_structure', 'report'],\n",
    "                      'Object_name': [model_name, temporal_block, stochastic_scenario, stochastic_structure, report_name]}\n",
    "df_reports = pd.DataFrame({\n",
    "    'Relationship_class_name': ['report__output']*len(reports_list),\n",
    "    'Object_class_name_1': ['report']*len(reports_list),\n",
    "    'Object_class_name_2': ['output']*len(reports_list),\n",
    "    'Object_name_1': [report_name]*len(reports_list),\n",
    "    'Object_name_2': reports_list\n",
    "})\n",
    "\n",
    "# Add everything else\n",
    "df_model_struc = pd.DataFrame({\n",
    "    'Relationship_class_name': ['model__temporal_block','model__default_temporal_block', \n",
    "                                'model__stochastic_structure', 'model__default_stochastic_structure',\n",
    "                                'stochastic_structure__stochastic_scenario', 'model__report'],\n",
    "    'Object_class_name_1': ['model','model','model','model','stochastic_structure','model'],\n",
    "    'Object_class_name_2': ['temporal_block', 'temporal_block','stochastic_structure','stochastic_structure', 'stochastic_scenario','report'],\n",
    "    'Object_name_1': [model_name, model_name,model_name,model_name,stochastic_structure, model_name],\n",
    "    'Object_name_2': [temporal_block, temporal_block, stochastic_structure, stochastic_structure, stochastic_scenario, report_name]\n",
    "})\n",
    "df_model_relations = pd.concat([df_model_struc, df_reports], axis=0)\n",
    "df_model_relations = df_model_relations.reset_index(drop=True)\n",
    "\n",
    "# Defining default investment temporal block and stochastic structure if investment = true\n",
    "if candidate_nonzero:\n",
    "    df_model_relations.loc[len(df_model_relations.index)] = ['model__default_investment_temporal_block', 'model', 'temporal_block', model_name, 'Default_Investment_period']\n",
    "    df_model_relations.loc[len(df_model_relations.index)] = ['model__default_investment_stochastic_structure', 'model', 'stochastic_structure', model_name, stochastic_structure]\n",
    "\n",
    "# Show table head for control\n",
    "df_model_relations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b88dc-3a5b-41c5-b184-64593c28c72c",
   "metadata": {},
   "source": [
    "#### Start, end, resolution :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960d14b-394b-4599-9e1e-8831aa59e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create values for model structure\n",
    "column_names_model = {'Object_class_name':['model','model','temporal_block'],\n",
    "                      'Object_name': [model_name, model_name, temporal_block],\n",
    "                      'Parameter':['model_start','model_end','resolution'],\n",
    "                      'Alternative': [scenario[0], scenario[0], scenario[0]],\n",
    "                      'Value': ['{\"type\": \"date_time\", \"data\": \"'+df_time.iloc[0]['DateTime']+'\"}',\n",
    "                          '{\"type\": \"date_time\", \"data\": \"'+df_time.iloc[-1]['DateTime']+'\"}', \n",
    "                          '{\"type\":\"duration\", \"data\": \"'+frequency+'\"}']}\n",
    "df_model = pd.DataFrame(column_names_model, index=None)\n",
    "\n",
    "# Add investment temporal blocks to model data frame in days if investment = true\n",
    "if candidate_nonzero:\n",
    "    df_model.loc[len(df_model.index)] = ['temporal_block', 'Default_Investment_period', 'resolution', scenario[0], '{\"type\":\"duration\", \"data\": \"'+convert_to_days(investment_period_default, year)+'\"}']\n",
    "\n",
    "# Show how table head for control\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24d678-4167-4521-a6ab-aae160dc13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information in case roll forward is used\n",
    "if roll_forward_use:\n",
    "    if temporal_block == 'hourly':\n",
    "        unit = 'h'\n",
    "    elif temporal_block == 'daily':\n",
    "        unit = 'D'\n",
    "    elif temporal_block == 'monthly':\n",
    "        unit = 'M'\n",
    "    else:\n",
    "        unit = ''\n",
    "        print(\"\\033[91mWARNING:\\033[0m Duration not defined!!!\")\n",
    "    # Add the new row to the df\n",
    "    roll_forward_size_with_unit = str(roll_forward_size) + unit\n",
    "    roll_forward_row = {'Object_class_name': 'model', \n",
    "                        'Object_name': model_name, \n",
    "                        'Parameter': 'roll_forward',\n",
    "                        'Alternative': scenario[0],\n",
    "                        'Value': '{\"type\": \"duration\", \"data\": \"' + roll_forward_size_with_unit +'\"}'\n",
    "                       }\n",
    "    # Add new row to df_model DataFrame\n",
    "    df_model.loc[len(df_model)] = roll_forward_row\n",
    "\n",
    "# Show table head for control\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14842492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal resolution for demand\n",
    "# Add temporal block to definition, if necessary\n",
    "df_model_units['resolution_output'].apply(lambda x: check_temporal_block(x, df_model_components))\n",
    "\n",
    "# Add temporal relation to respective node\n",
    "df_temporal_relations = pd.DataFrame(columns = ['Relationship_class_name', 'Node', 'Temporal_block'], index=None)\n",
    "df_model_units.apply(lambda row: create_temporal_block_relationships(row['resolution_output'],row['Output1'], df_model_relations, model_name, df_definition, df_temporal_relations),axis=1)\n",
    "\n",
    "# Add values to temporal block\n",
    "df_model_units['resolution_output'].apply(lambda x: create_temporal_block_input(x, df_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be54c5-1d66-4841-a002-30a94697b84e",
   "metadata": {},
   "source": [
    "### Variable Efficiency Units:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17268ecd-53bc-49ec-b6b8-6132ce181b2f",
   "metadata": {},
   "source": [
    "#### Calculate adjusted efficiency for each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb0765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Important as the SpineOpt implementation is piecewise but when producing at high capacity the lower segments also produce\n",
    "# This way, we avoid overestimation of production when running at higher capacities\n",
    "\n",
    "for index, row in df_model_units.iterrows():\n",
    "    if pd.notna(row['mean_efficiency']):\n",
    "        # If 'mean_efficiency' column has a value, check if corresponding DataFrame exists\n",
    "        column_name = row['Unit'].lower()\n",
    "        df_name = f\"df_efficiency_{column_name}\"\n",
    "        goal = row['mean_efficiency']\n",
    "        output_1 = row['Output1']\n",
    "        input_1 = row['Input1']\n",
    "        \n",
    "        if df_name in globals() and isinstance(globals()[df_name], pd.DataFrame):\n",
    "            \n",
    "            # Calculate adjusted efficiency\n",
    "            df_efficiency_adj = create_adj_efficiency(globals()[df_name], goal, column_name)\n",
    "            globals()[f\"df_efficiency_{column_name}_adj\"] = df_efficiency_adj\n",
    "            \n",
    "            # Fit with operating points\n",
    "            des_segment = globals()['des_segments_' + column_name]\n",
    "            df_var_efficiency, df_operating_points, segment_x_values, segment_averages, x_values, y_values = calculate_op_points(\n",
    "                column_name, des_segment, df_efficiency_adj, input_1, output_1\n",
    "            )\n",
    "            globals()[f\"variable_efficiency_{column_name}\"] = df_var_efficiency\n",
    "            globals()[f\"operating_points_{column_name}\"] = df_operating_points\n",
    "            globals()[f\"segment_x_values_{column_name}\"] = segment_x_values\n",
    "            globals()[f\"segment_averages_{column_name}\"] = segment_averages\n",
    "            globals()[f\"x_values_{column_name}\"] = x_values\n",
    "            globals()[f\"y_values_{column_name}\"] = y_values\n",
    "            \n",
    "            # Create ordered_unit_flow\n",
    "            ordered_unit_flow = check_decreasing(df_var_efficiency, column_name, input_1)\n",
    "            globals()[f\"ordered_unit_flow_{column_name}\"] = ordered_unit_flow\n",
    "            \n",
    "        else:\n",
    "            print(f\"WARNING: No variable efficiency defined for {column_name}\")\n",
    "    else:\n",
    "        # If 'mean_efficiency' column is NA, skip\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf17dac-b552-4369-84fc-4417439747a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the data of the original efficiency curve and the adjusted ones\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(df_efficiency_electrolyzer_adj['Power [%]'], df_efficiency_electrolyzer_adj['Efficiency [%]'], label='Eff raw', marker='o')\n",
    "plt.plot(df_efficiency_electrolyzer_adj['Power [%]'], df_efficiency_electrolyzer_adj['Efficiency_scaled [%]'], label='Eff scaled', marker='x')\n",
    "plt.plot(df_efficiency_adj['Power [%]'], df_efficiency_adj['eff_adjusted_electrolyzer'], label='Eff adjusted', marker='x', \n",
    "         linestyle='dashed', dashes=(5, 7))\n",
    "\n",
    "plt.xlabel('Power [%]')\n",
    "plt.ylabel('Efficiency [%]')\n",
    "plt.title('Efficiency vs Power')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data points and the curve\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(df_efficiency_electrolyzer_adj['Power [%]'], df_efficiency_electrolyzer_adj['eff_adjusted_electrolyzer'], color='blue', label='Efficiency Adjusted')\n",
    "plt.plot(x_values_electrolyzer, y_values_electrolyzer, color='red', label='Fitted Efficiency Curve Electrolyzer')\n",
    "\n",
    "# Plotting segment averages\n",
    "for i, (x_start, x_end) in enumerate(segment_x_values_electrolyzer):\n",
    "    plt.plot([x_start, x_end], [segment_averages_electrolyzer[i], segment_averages_electrolyzer[i]], color='green', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Curve Fitted to Data Points')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722bb069",
   "metadata": {},
   "source": [
    "#### Add operating points to user constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38694351",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Summarize all variable efficiencies\n",
    "# Collect all data frames that start with variable_efficiency\n",
    "dfs = [value for key, value in globals().items() if key.startswith('variable_efficiency') and isinstance(value, pd.DataFrame)]\n",
    "\n",
    "# Choose the first column with the most segments\n",
    "longest_df = max(dfs, key=lambda df: df.shape[0])\n",
    "first_column = longest_df.iloc[:, 0]\n",
    "\n",
    "# Concatenate the remaining columns from all DataFrames, ensuring no duplicate \"first column\"\n",
    "remaining_columns = [df.iloc[:, 1:] for df in dfs]\n",
    "\n",
    "# Concatenate the remaining columns to the longest first column\n",
    "df_variable_efficiency = pd.concat([first_column] + remaining_columns, axis=1)\n",
    "df_variable_efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b94c1a0-c73d-45b6-b048-df9ae8c0261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relate all user_constraints to entity class name \"user_constraint\" \n",
    "\n",
    "Entity_names_duplicate = df_variable_efficiency.iloc[0,1:]\n",
    "User_constraint_entities = []\n",
    "for name in Entity_names_duplicate:\n",
    "    if name not in User_constraint_entities:\n",
    "        User_constraint_entities.append(name)\n",
    "        \n",
    "\n",
    "User_constraint_column = [\"user_constraint\"]*len(User_constraint_entities)\n",
    "\n",
    "merged_columns = {\"Entity class names\": User_constraint_column, \"Entity names\": User_constraint_entities}\n",
    "df_variable_eff_def= pd.DataFrame(merged_columns)\n",
    "df_variable_eff_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarize all operating points\n",
    "# Collect all data frames that start with operating_points\n",
    "dfs = [value for key, value in globals().items() if key.startswith('operating_points') and isinstance(value, pd.DataFrame)]\n",
    "\n",
    "# Choose the first column with the most segments\n",
    "longest_df = max(dfs, key=lambda df: df.shape[0])\n",
    "first_column = longest_df.iloc[:, 0]\n",
    "\n",
    "# Concatenate the remaining columns from all DataFrames, ensuring no duplicate \"first column\"\n",
    "remaining_columns = [df.iloc[:, 1:] for df in dfs]\n",
    "\n",
    "# Concatenate the remaining columns to the longest first column\n",
    "df_operating_points = pd.concat([first_column] + remaining_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899403f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarize all ordered_unit_flow_op\n",
    "# Collect all data frames that start with ordered_unit_flow_op\n",
    "dfs = [value for key, value in globals().items() if key.startswith('ordered_unit_flow_') and isinstance(value, pd.DataFrame)]\n",
    "\n",
    "# Concatenate the remaining columns to the longest first column\n",
    "df_boolean_relations = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f878c0",
   "metadata": {},
   "source": [
    "### Environment and Storages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b06362-af38-4e4b-ab1b-fc2f8024bee0",
   "metadata": {},
   "source": [
    "#### Renewables Availability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c49bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table headers and relations\n",
    "column_names_1 = {'DateTime '+area: [None, None]}\n",
    "\n",
    "# Add time values\n",
    "df_temp_1 = pd.DataFrame(columns=['DateTime ' + area])\n",
    "df_temp_1['DateTime '+area] = df_time\n",
    "\n",
    "# Add solar values\n",
    "if 'Solar plant' in powers:\n",
    "    column_names_1['Solar_Plant'] = ['unit', 'unit_availability_factor']\n",
    "    df_temp_1['Solar_Plant'] = df_PV_availabilityfactors_values['unit_availability_factor']\n",
    "    \n",
    "    # Fill NaNs on last day by copying previous day (only for leap years)\n",
    "    df_temp_1['Solar_Plant_shifted'] = df_temp_1['Solar_Plant'].shift(24)\n",
    "    df_temp_1['Solar_Plant'] = df_temp_1['Solar_Plant'].fillna(df_temp_1['Solar_Plant_shifted'])\n",
    "    df_temp_1 = df_temp_1.drop(columns=['Solar_Plant_shifted'])\n",
    "\n",
    "# Add onshore wind values\n",
    "if 'Wind onshore' in powers:\n",
    "    column_names_1['Wind_onshore'] = ['unit', 'unit_availability_factor']\n",
    "    df_temp_1['Wind_onshore'] = df_wind_availabilityfactors_values['unit_availability_factor_onshore']\n",
    "    \n",
    "    # Fill NaNs on last day by copying previous day (only for leap years)\n",
    "    df_temp_1['Wind_onshore_shifted'] = df_temp_1['Wind_onshore'].shift(24)\n",
    "    df_temp_1['Wind_onshore'] = df_temp_1['Wind_onshore'].fillna(df_temp_1['Wind_onshore_shifted'])\n",
    "    df_temp_1 = df_temp_1.drop(columns=['Wind_onshore_shifted'])\n",
    "\n",
    "# Add offshore wind values\n",
    "if 'Wind offshore' in powers:\n",
    "    column_names_1['Wind_offshore'] = ['unit', 'unit_availability_factor']\n",
    "    df_temp_1['Wind_offshore'] = df_wind_availabilityfactors_values['unit_availability_factor_offshore']\n",
    "    \n",
    "    # Fill NaNs on last day by copying previous day (only for leap years)\n",
    "    df_temp_1['Wind_offshore_shifted'] = df_temp_1['Wind_offshore'].shift(24)\n",
    "    df_temp_1['Wind_offshore'] = df_temp_1['Wind_offshore'].fillna(df_temp_1['Wind_offshore_shifted'])\n",
    "    df_temp_1 = df_temp_1.drop(columns=['Wind_offshore_shifted'])\n",
    "\n",
    "\n",
    "#Add chosen availability factors to one combined dataframe\n",
    "df_blank_table_1 = pd.DataFrame(column_names_1, index=None)\n",
    "df_time_series = pd.concat([df_blank_table_1, df_temp_1])\n",
    "\n",
    "# Show table head for control\n",
    "df_time_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e74f16-846f-4ba0-b9c6-869e32be6676",
   "metadata": {},
   "source": [
    "#### Energy prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679f8e3-8ce3-4f00-b57e-e3f1427db970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustments of power price variance\n",
    "\n",
    "# Calculate the current mean and variance\n",
    "mean = df_powerprices_values['SpotPriceEUR'].mean()\n",
    "current_variance = df_powerprices_values['SpotPriceEUR'].var()\n",
    "\n",
    "# Define the new desired variance \n",
    "desired_variance = current_variance * power_price_variance\n",
    "\n",
    "# Calculate the scaling factor\n",
    "scaling_factor = np.sqrt(desired_variance / current_variance)\n",
    "\n",
    "# Adjust the time series to achieve the new variance\n",
    "df_powerprices_values['SpotPriceEUR'] = mean + (df_powerprices_values['SpotPriceEUR'] - mean) * scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785d20b-2cbe-4f0b-8842-2878a3335580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create table\n",
    "column_names_2 = {'DateTime ' + area: ['relationship class','connection','node','parameter name'],\n",
    "                'Power_Wholesale_In': ['connection__from_node','power_line_Wholesale_Kasso','Power_Wholesale','connection_flow_cost'], \n",
    "                'Power_Wholesale_Out': ['connection__to_node','power_line_Wholesale_Kasso','Power_Wholesale','connection_flow_cost'], \n",
    "                'District_Heating': ['connection__to_node','pipeline_District_Heating','District_Heating','connection_flow_cost']}\n",
    "df_blank_table_2 = pd.DataFrame(column_names_2, index=None)\n",
    "\n",
    "# Add values\n",
    "df_temp_2 = pd.DataFrame(columns=['DateTime ' + area, 'Power_Wholesale_In', 'Power_Wholesale_Out', 'District_Heating'])\n",
    "\n",
    "df_temp_2['DateTime ' + area] = df_time\n",
    "df_temp_2['Power_Wholesale_In'] = price_level_power * df_powerprices_values['SpotPriceEUR']\n",
    "df_temp_2['Power_Wholesale_Out'] = -1 * price_level_power * df_powerprices_values['SpotPriceEUR']\n",
    "df_temp_2['District_Heating'] = -1 * df_district_heating_price[str(year)].loc[2] * share_of_dh_price_cap\n",
    "\n",
    "df_table_2 = pd.concat([df_blank_table_2, df_temp_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add grid costs for consumption and production\n",
    "# Create table\n",
    "column_names_3 = {'Grid_costs_consumption': ['connection__to_node', 'power_line_Wholesale_Kasso', 'Power_Kasso', 'connection_flow_cost'],\n",
    "                 'Grid_costs_production': ['connection__from_node', 'power_line_Wholesale_Kasso', 'Power_Kasso', 'connection_flow_cost']}\n",
    "df_blank_table_3 = pd.DataFrame(column_names_3, index=None)\n",
    "\n",
    "# Add values\n",
    "df_temp_3 = pd.DataFrame(columns=['Grid_costs_consumption', 'Grid_costs_production'])\n",
    "\n",
    "df_temp_3['Grid_costs_consumption'] = df_grid_costs['consumption costs']\n",
    "df_temp_3['Grid_costs_production'] = df_grid_costs['production costs']\n",
    "\n",
    "df_table_3 = pd.concat([df_blank_table_3, df_temp_3], ignore_index = True)\n",
    "\n",
    "# Merge all energy prices\n",
    "df_energy_prices = pd.concat([df_table_2, df_table_3], axis = 1)\n",
    "\n",
    "# Show table head for control\n",
    "df_energy_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6190d8",
   "metadata": {},
   "source": [
    "#### Units on costs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1031bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add units on costs for all units that have either min_down_time, ramp_up/down_limits, or start_up/shut_down limits/costs\n",
    "# Filter units_parameter_df and df_object__node\n",
    "cost_parameters = ['min_down_time', 'min_up_time', 'shut_down_cost', 'start_up_cost', \n",
    "                   'ramp_down_limit', 'ramp_up_limit', 'start_up_limit', 'shut_down_limit']\n",
    "filtered_units_parameter_df = unit_parameters_df[unit_parameters_df['Parameter'].isin(cost_parameters)]\n",
    "filtered_df_object__node = df_object__node[df_object__node['Parameter'].isin(cost_parameters)]\n",
    "\n",
    "combined_object_names = pd.concat([filtered_units_parameter_df['Object_name'], filtered_df_object__node['Object_name']])\n",
    "unique_objects = combined_object_names.unique()\n",
    "\n",
    "# Check if they already have a units_on_cost value other than 0\n",
    "non_zero_units_df = unit_parameters_df[(unit_parameters_df['Parameter'] == 'units_on_cost') & \n",
    "                                       (unit_parameters_df['Value'] != 0.0)]\n",
    "non_zero_units = non_zero_units_df['Object_name'].unique()\n",
    "\n",
    "# Remove units_on_cost = 0 from unit_parameters_df if in unique_objects\n",
    "unit_parameters_df = unit_parameters_df[~(\n",
    "    (unit_parameters_df['Parameter'] == 'units_on_cost') & \n",
    "    (unit_parameters_df['Value'] == 0) & \n",
    "    (unit_parameters_df['Object_name'].isin(unique_objects))\n",
    ")]\n",
    "\n",
    "unique_units = [unit for unit in unique_objects if unit not in non_zero_units]\n",
    "\n",
    "# Create new columns for each unique unit in df_time_series\n",
    "for unit in unique_units:\n",
    "    unit_data = [\"unit\", \"units_on_cost\"]\n",
    "    \n",
    "    power_data = df_temp_2['Power_Wholesale_In'].tolist()\n",
    "    \n",
    "    #df_time_series[unit] = unit_data + power_data\n",
    "    # Reset the index of df_time_series to avoid non-unique index error\n",
    "    df_time_series = df_time_series.reset_index(drop=True)\n",
    "    # Create a temporary DataFrame for the new column\n",
    "    new_column = pd.DataFrame({unit: unit_data + power_data})\n",
    "    # Ensure the new column has the same length as df_time_series\n",
    "    new_column = new_column.reindex(df_time_series.index)\n",
    "    # Use pd.concat to add new columns without overwriting existing ones\n",
    "    df_time_series = pd.concat([df_time_series, new_column], axis=1)\n",
    "\n",
    "\n",
    "# Show table head for control\n",
    "df_time_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df00bdab-f254-437f-b78d-d32b19e2f9db",
   "metadata": {},
   "source": [
    "#### Time Series Storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date index\n",
    "start_date = pd.to_datetime(start_date)\n",
    "before = start_date-timedelta(hours=1)\n",
    "date_index_beginning = pd.date_range(start=before, end=start_date, freq='H')\n",
    "formatted_beginning = date_index_beginning.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "df_formatted_beginning = pd.DataFrame(formatted_beginning, columns=['DateTime'])\n",
    "df_time_beginning = pd.DataFrame(df_formatted_beginning)\n",
    "# Add one blank row\n",
    "new_row = pd.Series([])\n",
    "df_time_beginning = pd.concat([pd.DataFrame([new_row]), df_time_beginning]).reset_index(drop=True)\n",
    "\n",
    "# Concat raw data with time index\n",
    "storage_values = df_model_storages.iloc[:,[0, 1, 2, 6]]\n",
    "storage_values = storage_values.iloc[:, [0, 3, 1, 2]]\n",
    "storage_values_transposed = storage_values.T\n",
    "storage_values_transposed.columns = storage_values_transposed.iloc[0]\n",
    "storage_values_transposed = storage_values_transposed[1:]\n",
    "storage_values_transposed.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_storage = pd.concat([df_time_beginning, storage_values_transposed], axis=1)\n",
    "\n",
    "# Show table head for control\n",
    "df_storage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dfbf3e-1928-4547-8b3a-dac782ca46a3",
   "metadata": {},
   "source": [
    "## Creating one combined excel and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523a4cd-ad6f-44d6-993d-3ebaf00680c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prepared input excel for the use in SpineToolbox\n",
    "with pd.ExcelWriter(output_file_path + output_file_name) as writer:\n",
    "    df_definition.to_excel(writer, sheet_name='Definition', index=False)\n",
    "    unit_parameters_rest_df.to_excel(writer, sheet_name='Definition_parameters', index=False)\n",
    "    unit_parameters_duration_df.to_excel(writer, sheet_name='Definition_parameters_duration', index=False)\n",
    "    df_units_inv_parameters.to_excel(writer, sheet_name='Unit_Inv_Parameters', index=False)\n",
    "    df_nodes.to_excel(writer, sheet_name='Nodes', index=False)\n",
    "    df_connections_inv_parameters.to_excel(writer, sheet_name='Connection_Inv_Parameters', index=False)\n",
    "    df_object__node_definitions.to_excel(writer, sheet_name='Object__to_from_node_definition', index=False)\n",
    "    df_object__node_values.to_excel(writer, sheet_name='Object__to_from_node', index=False)\n",
    "    df_boolean_relations.to_excel(writer, sheet_name='Boolean_relations', index=False)\n",
    "    df_object_node_node.to_excel(writer, sheet_name='Object__node_node', index=False)\n",
    "    df_variable_eff_def.to_excel(writer, sheet_name='Variable_Eff_Definition', index=False)\n",
    "    df_variable_efficiency.to_excel(writer, sheet_name='Variable_Eff', index=False)\n",
    "    df_operating_points.to_excel(writer, sheet_name='Operating_points', index=False)\n",
    "    df_storage.to_excel(writer, sheet_name='Time_series_storage', index=False)\n",
    "    df_time_series.to_excel(writer, sheet_name='Time_series', index=False)\n",
    "    df_energy_prices.to_excel(writer, sheet_name='Energy_prices', index=False)\n",
    "    df_model_components.to_excel(writer, sheet_name='Model_components', index=False)\n",
    "    df_model_relations.to_excel(writer, sheet_name='Model_relations', index=False)\n",
    "    df_model.to_excel(writer, sheet_name='Model', index=False)\n",
    "    df_temporal_relations.to_excel(writer, sheet_name='Temporal_relations', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecfd010-a65f-4cfc-8ec2-a7d3bbded502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output of the mapping excel\n",
    "with pd.ExcelWriter(output_file_path + output_mapping_file_name) as writer:\n",
    "    df_model_object_mapping.to_excel(writer, sheet_name='Object_Mapping', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd66540-33e4-4200-8c13-6ee0ed292334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy efficiency\n",
    "other_name = \"other.xlsx\"\n",
    "with pd.ExcelWriter(output_file_path + other_name) as writer:\n",
    "    df_efficiency_electrolyzer_adj.to_excel(writer, sheet_name='efficiency', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
