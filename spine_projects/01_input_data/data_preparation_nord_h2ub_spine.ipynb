{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ea4b8f-0ba4-4513-8872-53f4a538a0d3",
   "metadata": {},
   "source": [
    "# Data Preparation for the Nord_H2ub Spine Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa86773-4431-4a2f-9490-4b3cf0aa8d70",
   "metadata": {},
   "source": [
    "This jupyter notebook contains all routines for the preparation of the input data sources into a input data file for the model in Spine. \n",
    "\n",
    "**Authors:** Johannes Giehl (jfg.eco@cbs.dk), Dana J. Hentschel (djh.eco@cbs.dk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8175ae-f246-4788-a309-c1a4890992f2",
   "metadata": {},
   "source": [
    "## General settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc68f78-3383-4889-bd9e-8b3e3e2f6c2e",
   "metadata": {},
   "source": [
    "### Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f47a1c-073f-46c0-8a4d-7dafb1716b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92141795-3716-404e-8e35-a096dcaa0c40",
   "metadata": {},
   "source": [
    "### Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e57da7-2051-45db-b50c-ef0d2603f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the functions and methods from the corresponding file\n",
    "from nord_h2ub_data_preparation_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50630f-868b-40f0-842e-c74d936b5d54",
   "metadata": {},
   "source": [
    "### Base parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5678470b-cd0b-4b6f-b698-2f166d1afd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define year and create time stamp\n",
    "year = 2019   #change to desired year\n",
    "start_date = pd.Timestamp(str(year) + '-01-01 00:00:00')\n",
    "end_date = pd.Timestamp(str(year) + '-12-31 23:00:00')\n",
    "#set area\n",
    "area = 'DK1'   #change to desired area\n",
    "#set product\n",
    "product = 'methanol'   #change to desired product\n",
    "#scenario\n",
    "scenario = 'Base'\n",
    "#frequency model\n",
    "frequency = '1h'\n",
    "#model name\n",
    "model_name = 'toy'\n",
    "#temporal block\n",
    "temporal_block = 'hourly'\n",
    "#stochastics\n",
    "stochastic_scenario = \"realisation\"\n",
    "stochastic_structure = \"deterministic\"\n",
    "#required reports\n",
    "report_name = 'Report'\n",
    "reports = ['unit_flow', 'connection_flow', 'node_state', 'total_costs', 'unit_flow_op']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56b541-1fbd-4e7e-9cf3-2ff25f8da472",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b811bdc-ac7b-4cd7-8e32-8f84bda412a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path to correct folders\n",
    "\n",
    "#input data\n",
    "excel_file_path = '../01_input_data/01_input_raw/'\n",
    "#prepared input data\n",
    "output_file_path = '../01_input_data/02_input_prepared/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89169e64-f204-47bb-9a83-17156a4aefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set name of the relevant files\n",
    "\n",
    "Model_structure_file = '/Model_Data_Base.xlsx'\n",
    "variable_efficiency_file = '/variable_efficiency.xlsx'\n",
    "\n",
    "PV_data_availabilityfactors = 'PV_availability_factors_Kasso_' + str(year) + '.xlsx'\n",
    "data_powerprices = 'Day_ahead_prices_' + str(year) + '.xlsx'\n",
    "\n",
    "#output file\n",
    "output_file_name = product+'_Input_prepared.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d15fe8-064f-4c28-be28-8d924a4ba31b",
   "metadata": {},
   "source": [
    "\n",
    "## Workflow of the data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ad49f-470e-4b29-aa02-c7babb08befb",
   "metadata": {},
   "source": [
    "### General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50f50c3-e43d-41c2-8158-75596632213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date index\n",
    "date_index = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "formatted_dates = date_index.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "df_formatted_dates = pd.DataFrame(formatted_dates, columns=['DateTime'])\n",
    "\n",
    "df_time = pd.DataFrame(df_formatted_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb746a-7cd3-4655-88cf-ac543b003918",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42c5077-74ef-4f63-b6d9-4aa3c11aa878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the model structure from a new excel\n",
    "df_model_units = pd.read_excel(excel_file_path + product + Model_structure_file, sheet_name='Units', index_col=None)\n",
    "df_model_connections = pd.read_excel(excel_file_path + product + Model_structure_file, sheet_name='Connections', index_col=None)\n",
    "df_model_storages = pd.read_excel(excel_file_path + product + Model_structure_file, sheet_name='Storages', index_col=None)\n",
    "#Variable efficiency\n",
    "df_variable_efficiency = pd.read_excel(excel_file_path + product + variable_efficiency_file, sheet_name='Variable_Eff', header=None)\n",
    "#Availability factor\n",
    "df_PV_availabilityfactors_values = pd.read_excel(excel_file_path+PV_data_availabilityfactors, skiprows=2, usecols=[0,1,2,3,4,5])\n",
    "#Power prices\n",
    "df_powerprices_total_values = pd.read_excel(excel_file_path+data_powerprices)\n",
    "#only extracting the prices from our earlier defined area\n",
    "df_powerprices_values = df_powerprices_total_values[df_powerprices_total_values['PriceArea'] == area]\n",
    "df_powerprices_values = df_powerprices_values.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2693fc2-fe36-47a1-9b08-00f73dd53b9f",
   "metadata": {},
   "source": [
    "### Adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28376bad-520d-4ab3-85ce-2d1cf91ac5e5",
   "metadata": {},
   "source": [
    "#### Adjust base elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee53885-7c29-4a6e-b4a2-b4deeef30be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Name</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar_Plant_Kasso</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO2_Vaporizer</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Destilation_Tower</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Object_Name Category\n",
       "0  Solar_Plant_Kasso     unit\n",
       "1       Electrolyzer     unit\n",
       "2      CO2_Vaporizer     unit\n",
       "3  Destilation_Tower     unit\n",
       "4   Methanol_Reactor     unit"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe for units\n",
    "df_units = df_model_units[['Unit']].copy()\n",
    "df_units['Category'] = 'unit'\n",
    "#df_units['fom_cost'] = df_model_units[['fom_cost']]\n",
    "df_units = df_units.rename(columns={'Unit': 'Object_Name'})\n",
    "\n",
    "#Create a dataframe for connections\n",
    "df_connections = df_model_connections[['Connection']].copy()\n",
    "df_connections['Category'] = 'connection'\n",
    "df_connections = df_connections.rename(columns={'Connection': 'Object_Name'})\n",
    "#df_connections['fom_cost'] = df_model_connections[['fom_cost']]\n",
    "\n",
    "#create a list of nodes of the model\n",
    "U_input1_nodes = df_model_units['Input1'].tolist()\n",
    "U_input2_nodes = df_model_units['Input2'].tolist()\n",
    "U_output1_nodes = df_model_units['Output1'].tolist()\n",
    "U_output2_nodes = df_model_units['Output2'].tolist()\n",
    "C_input1_nodes = df_model_connections['Input1'].tolist()\n",
    "C_input2_nodes = df_model_connections['Input2'].tolist()\n",
    "C_output1_nodes = df_model_connections['Output1'].tolist()\n",
    "C_output2_nodes = df_model_connections['Output2'].tolist()\n",
    "\n",
    "# Combine values from both columns into a single list\n",
    "All_nodes_list = U_input1_nodes+U_input2_nodes+U_output1_nodes+U_output2_nodes+C_input1_nodes+C_input2_nodes+C_output1_nodes+C_output2_nodes\n",
    "\n",
    "# Create a list with unique entries\n",
    "unique_nodes_list = list(set(All_nodes_list))\n",
    "\n",
    "#Create a dataframe for nodes\n",
    "df_nodes = pd.DataFrame(unique_nodes_list, columns=['Object_Name'])\n",
    "df_nodes['Category'] = 'node'\n",
    "df_nodes = df_nodes.dropna()\n",
    "\n",
    "#Combined dataframe\n",
    "df_definition = pd.concat([df_units, df_nodes, df_connections], ignore_index=True)\n",
    "\n",
    "df_definition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c90d86-d62f-49aa-bf8c-a7ceec921d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jfg.eco\\Documents\\GitHub\\Nord_H2ub\\spine_projects\\01_input_data\\nord_h2ub_data_preparation_functions.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  unit_parameter_df = pd.concat([unit_parameter_df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "C:\\Users\\jfg.eco\\Documents\\GitHub\\Nord_H2ub\\spine_projects\\01_input_data\\nord_h2ub_data_preparation_functions.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  unit_parameter_df = pd.concat([unit_parameter_df, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>parameter</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar_Plant_Kasso</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit</td>\n",
       "      <td>min_down_time</td>\n",
       "      <td>48h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit</td>\n",
       "      <td>online_variable_type</td>\n",
       "      <td>unit_online_variable_type_integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power_line_Wholesale_Kasso</td>\n",
       "      <td>connection</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Object_Name    Category             parameter  \\\n",
       "0           Solar_Plant_Kasso        unit              fom_cost   \n",
       "1                Electrolyzer        unit              fom_cost   \n",
       "2            Methanol_Reactor        unit              fom_cost   \n",
       "3            Methanol_Reactor        unit         min_down_time   \n",
       "4            Methanol_Reactor        unit  online_variable_type   \n",
       "5  power_line_Wholesale_Kasso  connection              fom_cost   \n",
       "\n",
       "                               value  \n",
       "0                               1.29  \n",
       "1                               4.34  \n",
       "2                               4.45  \n",
       "3                                48h  \n",
       "4  unit_online_variable_type_integer  \n",
       "5                              100.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a data frame for all parameters of units\n",
    "\n",
    "#add fixed operation and maintenance cost\n",
    "unit_fom_cost_df = create_unit_parameters(df_model_units, 'Unit', 'fom_cost')\n",
    "#add unit minimal downtime\n",
    "unit_min_down_time_df = create_unit_parameters(df_model_units, 'Unit', 'min_down_time')\n",
    "#add unit on cost\n",
    "unit_on_cost_df = create_unit_parameters(df_model_units, 'Unit', 'unit_on_cost')\n",
    "\n",
    "connection_fom_cost_df = create_unit_parameters(df_model_connections, 'Connection', 'fom_cost')\n",
    "\n",
    "#create a complete data frame with all parameters\n",
    "unit_parameters_df = pd.concat([unit_fom_cost_df, unit_on_cost_df, unit_min_down_time_df, connection_fom_cost_df], ignore_index=True)\n",
    "unit_parameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "470215f7-7b7f-45f3-a1b6-daa11589ff79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>parameter</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solar_Plant_Kasso</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electrolyzer</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Methanol_Reactor</td>\n",
       "      <td>unit</td>\n",
       "      <td>online_variable_type</td>\n",
       "      <td>unit_online_variable_type_integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power_line_Wholesale_Kasso</td>\n",
       "      <td>connection</td>\n",
       "      <td>fom_cost</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Object_Name    Category             parameter  \\\n",
       "0           Solar_Plant_Kasso        unit              fom_cost   \n",
       "1                Electrolyzer        unit              fom_cost   \n",
       "2            Methanol_Reactor        unit              fom_cost   \n",
       "4            Methanol_Reactor        unit  online_variable_type   \n",
       "5  power_line_Wholesale_Kasso  connection              fom_cost   \n",
       "\n",
       "                               value  \n",
       "0                               1.29  \n",
       "1                               4.34  \n",
       "2                               4.45  \n",
       "4  unit_online_variable_type_integer  \n",
       "5                              100.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new data frame for parameters that are given as durations\n",
    "#necessary as SpineToolbox needs a separate input to map the parameter correctly\n",
    "\n",
    "duration_parameter = 'min_down_time'\n",
    "unit_parameters_duration_df = unit_parameters_df[unit_parameters_df['parameter'] == duration_parameter]\n",
    "# Resetting the index\n",
    "unit_parameters_duration_df = unit_parameters_duration_df.reset_index(drop=True)\n",
    "\n",
    "# Creating another DataFrame with rows that do not meet the condition\n",
    "unit_parameters_rest_df = unit_parameters_df[unit_parameters_df['parameter'] != duration_parameter]\n",
    "unit_parameters_rest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d4e42d4-76d0-480d-b7b2-bdb413adfc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the balance type of the nodes\n",
    "columns_to_select = ['Input1', 'Input2', 'Output1', 'Output2']\n",
    "df_combined = pd.concat([df_model_units, df_model_connections])\n",
    "df_combined = df_combined.reset_index(drop=True)\n",
    "\n",
    "df_nodes_network = create_connection_dataframe(df_combined, columns_to_select)\n",
    "\n",
    "# Get unique values from the 'in' column\n",
    "unique_in_values = df_nodes_network['in'].dropna().unique()\n",
    "\n",
    "# Identify values in 'in' column not present in 'out' column\n",
    "values_not_in_out = unique_in_values[~pd.Series(unique_in_values).isin(df_nodes_network['out'].dropna().unique())]\n",
    "\n",
    "# Get unique values from the 'in' column\n",
    "unique_out_values = df_nodes_network['out'].dropna().unique()\n",
    "\n",
    "# Identify values in 'in' column not present in 'out' column\n",
    "values_not_in_in = unique_out_values[~pd.Series(unique_out_values).isin(df_nodes_network['in'].dropna().unique())]\n",
    "\n",
    "#create list of unique nodes that are either start or end nodes\n",
    "unique_nodes = values_not_in_out.tolist() + values_not_in_in.tolist()\n",
    "unique_nodes\n",
    "\n",
    "df_nodes_network.replace(np.nan, None, inplace=True)\n",
    "\n",
    "#check for combinations that are mirrored\n",
    "mirrored_combinations = find_mirror_combinations(df_nodes_network)\n",
    "\n",
    "#get information of connections for each node\n",
    "partners_dict1 = find_partners(df_nodes_network)\n",
    "partners_dict2 = find_partners(mirrored_combinations)\n",
    "\n",
    "#check both lists if there are identical entries and list nodes that only have a connection to the same node\n",
    "#storages are removed as they must be balanced\n",
    "nodes_identical = find_identical_entries(partners_dict1, partners_dict2)\n",
    "\n",
    "#combined list of start and end nodes that should be unbalanced\n",
    "unbalanced_nodes = nodes_identical + unique_nodes\n",
    "\n",
    "df_nodes['balance_type'] = 'balance_type_node'\n",
    "df_nodes.loc[df_nodes['Object_Name'].isin(unbalanced_nodes), 'balance_type'] = 'balance_type_none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0403b80a-9d3f-4557-bda6-2803650bea2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>balance_type</th>\n",
       "      <th>has_state</th>\n",
       "      <th>node_state_cap</th>\n",
       "      <th>frac_state_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hydrogen_storage_Kasso</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>true</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>District_Heating</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Power_Kasso</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hydrogen_Kasso</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vaporized_Carbon_Dioxide</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Object_Name Category       balance_type has_state  \\\n",
       "0    Hydrogen_storage_Kasso     node  balance_type_node      true   \n",
       "1          District_Heating     node  balance_type_none       NaN   \n",
       "2               Power_Kasso     node  balance_type_node       NaN   \n",
       "3            Hydrogen_Kasso     node  balance_type_node       NaN   \n",
       "4  Vaporized_Carbon_Dioxide     node  balance_type_node       NaN   \n",
       "\n",
       "   node_state_cap  frac_state_loss  \n",
       "0        100000.0              0.0  \n",
       "1             NaN              NaN  \n",
       "2             NaN              NaN  \n",
       "3             NaN              NaN  \n",
       "4             NaN              NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add has_state_node_state_cap and frac_state_loss\n",
    "df_storages_short = df_model_storages.loc[:, ['Storage', 'has_state', 'node_state_cap', 'frac_state_loss']].rename(columns={'Storage': 'Object_Name'})\n",
    "df_storages_short['has_state'] = df_storages_short['has_state'].astype(str).str.lower().replace('true', 'true')\n",
    "\n",
    "df_nodes = pd.merge(df_nodes, df_storages_short, on='Object_Name', how='left')\n",
    "df_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb44a55f-bd0d-41f3-a96a-2fc67ae92a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>balance_type</th>\n",
       "      <th>has_state</th>\n",
       "      <th>node_state_cap</th>\n",
       "      <th>frac_state_loss</th>\n",
       "      <th>node_slack_penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hydrogen_storage_Kasso</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>true</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>District_Heating</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Power_Kasso</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hydrogen_Kasso</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vaporized_Carbon_Dioxide</td>\n",
       "      <td>node</td>\n",
       "      <td>balance_type_node</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Object_Name Category       balance_type has_state  \\\n",
       "0    Hydrogen_storage_Kasso     node  balance_type_node      true   \n",
       "1          District_Heating     node  balance_type_none       NaN   \n",
       "2               Power_Kasso     node  balance_type_node       NaN   \n",
       "3            Hydrogen_Kasso     node  balance_type_node       NaN   \n",
       "4  Vaporized_Carbon_Dioxide     node  balance_type_node       NaN   \n",
       "\n",
       "   node_state_cap  frac_state_loss node_slack_penalty  \n",
       "0        100000.0              0.0             100000  \n",
       "1             NaN              NaN                     \n",
       "2             NaN              NaN             100000  \n",
       "3             NaN              NaN             100000  \n",
       "4             NaN              NaN             100000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe with all nodes that should have a slack based on the unit input and outputs\n",
    "nodes_for_slack_df = check_entries_exist(df_model_units, 'node')\n",
    "#merge the information into the prepared data frame\n",
    "merged_df = pd.merge(df_nodes, nodes_for_slack_df, left_on='Object_Name', right_on='node', how='left')\n",
    "merged_df = merged_df.drop(columns=['node'])\n",
    "merged_df['node_slack_penalty'] = merged_df['node_slack_penalty'].replace({True: 100000, False: ''})\n",
    "#create a dataframe with all nodes that should have a slack based on the connection input and outputs\n",
    "nodes_for_slack_df2 = check_entries_exist(df_model_connections, 'connection')\n",
    "#merge the information into the prepared data frame\n",
    "merged_df2 = pd.merge(df_nodes, nodes_for_slack_df2, left_on='Object_Name', right_on='connection', how='left')\n",
    "merged_df2 = merged_df2.drop(columns=['connection'])\n",
    "merged_df2['node_slack_penalty'] = merged_df2['node_slack_penalty'].replace({True: 100000, False: ''})\n",
    "#link the information about the slack of both data frames\n",
    "merged_df2['node_slack_penalty'] = merged_df['node_slack_penalty'].combine_first(merged_df2['node_slack_penalty'])\n",
    "#clean the information that only nodes with 'balance_type_node' have a penalty\n",
    "merged_df2.loc[merged_df2['balance_type'] == 'balance_type_none', 'node_slack_penalty'] = ''\n",
    "#add the information into the df_nodes\n",
    "df_nodes['node_slack_penalty'] = merged_df2['node_slack_penalty']\n",
    "\n",
    "#show table head for control\n",
    "df_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee8799cc-183e-408a-a903-32f8f6e56693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Connection</th>\n",
       "      <th>Parameter_name</th>\n",
       "      <th>Connection_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>power_line_Wholesale_Kasso</td>\n",
       "      <td>connection_type</td>\n",
       "      <td>connection_type_lossless_bidirectional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pipeline_storage_hydrogen</td>\n",
       "      <td>connection_type</td>\n",
       "      <td>connection_type_lossless_bidirectional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pipeline_storage_e-methanol</td>\n",
       "      <td>connection_type</td>\n",
       "      <td>connection_type_lossless_bidirectional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pipeline_District_Heating</td>\n",
       "      <td>connection_type</td>\n",
       "      <td>connection_type_normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Connection   Parameter_name  \\\n",
       "0   power_line_Wholesale_Kasso  connection_type   \n",
       "1    pipeline_storage_hydrogen  connection_type   \n",
       "2  pipeline_storage_e-methanol  connection_type   \n",
       "3    pipeline_District_Heating  connection_type   \n",
       "\n",
       "                          Connection_type  \n",
       "0  connection_type_lossless_bidirectional  \n",
       "1  connection_type_lossless_bidirectional  \n",
       "2  connection_type_lossless_bidirectional  \n",
       "3                  connection_type_normal  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add parameters for connections\n",
    "df_connections = df_model_connections.loc[:, ['Connection', 'Connection_type']]\n",
    "insert_index=1\n",
    "parameter_name = ['connection_type']*len(df_connections)\n",
    "df_connections.insert(insert_index, 'Parameter_name', parameter_name)\n",
    "#show table for control\n",
    "df_connections.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f3dc6-ea13-486b-9860-6bd41f57b3a7",
   "metadata": {},
   "source": [
    "#### Times series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e60a7947-9d7f-480f-847a-f22419719660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust PV columns names\n",
    "df_PV_availabilityfactors_values.rename(columns={'time': 'time [UTC]', \n",
    "                                                 'local_time': 'time [' + area + ']',\n",
    "                                                 'electricity': 'unit_availability_factor'}, inplace=True)\n",
    "df_powerprices_values.rename(columns={'HourUTC': 'time [UTC]', \n",
    "                                         'HourDK': 'time [' + area + ']'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b3c37-228f-47f0-a99e-2df1f87512d5",
   "metadata": {},
   "source": [
    "### Fitting data into format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b527344-851f-47c0-a12e-72942d4176eb",
   "metadata": {},
   "source": [
    "#### Relationships:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea16b2-0e98-4ca2-b6ec-aa840ac09d20",
   "metadata": {},
   "source": [
    "Object__from/to_node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e0a59d6-76be-4405-8ef7-62428bbe25ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'minimum_op_point_Output1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Gurobi\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'minimum_op_point_Output1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m start_up_output \u001b[38;5;241m=\u001b[39m row[start_up_output_col]\n\u001b[0;32m     56\u001b[0m shut_down_output \u001b[38;5;241m=\u001b[39m row[shut_down_output_col]\n\u001b[1;32m---> 57\u001b[0m minimum_op_output \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mminimum_op_point_col\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(output_value):\n\u001b[0;32m     60\u001b[0m     unit_relation_parameter_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelationship_class_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munit__to_node\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m: output_capacity \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(output_capacity) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     67\u001b[0m     })\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Gurobi\\Lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Gurobi\\Lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Gurobi\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'minimum_op_point_Output1'"
     ]
    }
   ],
   "source": [
    "### UNITS ###\n",
    "# Initialize an empty list to store the transformed data\n",
    "unit_relation_parameter_data = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_model_units.iterrows():\n",
    "    unit = row['Unit']\n",
    "\n",
    "    # Iterate over Input and Output columns\n",
    "    for i in range(1, 3):\n",
    "        input_col = f'Input{i}'\n",
    "        output_col = f'Output{i}'\n",
    "        cap_input_col = f'Cap_{input_col}_existing'\n",
    "        cap_output_col = f'Cap_{output_col}_existing'\n",
    "        vom_cost_input_col = f'vom_cost_{input_col}'\n",
    "        vom_cost_output_col = f'vom_cost_{output_col}'\n",
    "        ramp_up_output_col = f'ramp_up_{output_col}'\n",
    "        ramp_down_output_col = f'ramp_down_{output_col}'\n",
    "        start_up_output_col = f'start_up_{output_col}'\n",
    "        shut_down_output_col = f'shut_down_{output_col}'\n",
    "        minimum_op_point_col = f'minimum_op_point_{output_col}'\n",
    "\n",
    "        # Check for Input columns\n",
    "        input_value = row[input_col]\n",
    "        input_capacity = row[cap_input_col]\n",
    "        vom_cost_input = row[vom_cost_input_col]\n",
    "\n",
    "        if pd.notna(input_value):\n",
    "            unit_relation_parameter_data.append({\n",
    "                'Relationship_class_name': 'unit__from_node',\n",
    "                'Object_class': 'unit',\n",
    "                'Object_name': unit,\n",
    "                'Node': input_value,\n",
    "                'Parameter': 'unit_capacity' if pd.notna(input_capacity) else '',\n",
    "                'Value': input_capacity if pd.notna(input_capacity) else ''\n",
    "            })\n",
    "        \n",
    "            if pd.notna(input_value) and pd.notna(vom_cost_input):\n",
    "                unit_relation_parameter_data.append({\n",
    "                    'Relationship_class_name': 'unit__from_node',\n",
    "                    'Object_class': 'unit',\n",
    "                    'Object_name': unit,\n",
    "                    'Node': input_value,\n",
    "                    'Parameter': 'vom_cost',\n",
    "                    'Value': vom_cost_input\n",
    "                })\n",
    "\n",
    "\n",
    "        # Check for Output columns\n",
    "        output_value = row[output_col]\n",
    "        output_capacity = row[cap_output_col]\n",
    "        vom_cost_output = row[vom_cost_output_col]\n",
    "        ramp_up_output = row[ramp_up_output_col]\n",
    "        ramp_down_output = row[ramp_down_output_col]\n",
    "        start_up_output = row[start_up_output_col]\n",
    "        shut_down_output = row[shut_down_output_col]\n",
    "        minimum_op_output = row[minimum_op_point_col]\n",
    "\n",
    "        if pd.notna(output_value):\n",
    "            unit_relation_parameter_data.append({\n",
    "                'Relationship_class_name': 'unit__to_node',\n",
    "                'Object_class': 'unit',\n",
    "                'Object_name': unit,\n",
    "                'Node': output_value,\n",
    "                'Parameter': 'unit_capacity' if pd.notna(output_capacity) else '',\n",
    "                'Value': output_capacity if pd.notna(output_capacity) else ''\n",
    "            })\n",
    "        \n",
    "            if pd.notna(output_value) and pd.notna(vom_cost_output):\n",
    "                unit_relation_parameter_data.append({\n",
    "                    'Relationship_class_name': 'unit__to_node',\n",
    "                    'Object_class': 'unit',\n",
    "                    'Object_name': unit,\n",
    "                    'Node': output_value,\n",
    "                    'Parameter': 'vom_cost',\n",
    "                    'Value': vom_cost_output\n",
    "                })\n",
    "\n",
    "            if pd.notna(output_value) and pd.notna(ramp_up_output):\n",
    "                unit_relation_parameter_data.append({\n",
    "                    'Relationship_class_name': 'unit__to_node',\n",
    "                    'Object_class': 'unit',\n",
    "                    'Object_name': unit,\n",
    "                    'Node': output_value,\n",
    "                    'Parameter': 'ramp_up_limit',\n",
    "                    'Value': ramp_up_output\n",
    "                })\n",
    "\n",
    "            if pd.notna(output_value) and pd.notna(ramp_down_output):\n",
    "                unit_relation_parameter_data.append({\n",
    "                    'Relationship_class_name': 'unit__to_node',\n",
    "                    'Object_class': 'unit',\n",
    "                    'Object_name': unit,\n",
    "                    'Node': output_value,\n",
    "                    'Parameter': 'ramp_down_limit',\n",
    "                    'Value': ramp_down_output\n",
    "                })\n",
    "            \n",
    "            if pd.notna(output_value) and pd.notna(start_up_output):\n",
    "                unit_relation_parameter_data.append({\n",
    "                    'Relationship_class_name': 'unit__to_node',\n",
    "                    'Object_class': 'unit',\n",
    "                    'Object_name': unit,\n",
    "                    'Node': output_value,\n",
    "                    'Parameter': 'start_up_limit',\n",
    "                    'Value': start_up_output\n",
    "                })\n",
    "            \n",
    "            if pd.notna(output_value) and pd.notna(shut_down_output):\n",
    "                unit_relation_parameter_data.append({\n",
    "                    'Relationship_class_name': 'unit__to_node',\n",
    "                    'Object_class': 'unit',\n",
    "                    'Object_name': unit,\n",
    "                    'Node': output_value,\n",
    "                    'Parameter': 'shut_down_limit',\n",
    "                    'Value': shut_down_output\n",
    "                })\n",
    "            if pd.notna(output_value) and pd.notna(minimum_op_output):\n",
    "                unit_relation_parameter_data.append({\n",
    "                    'Relationship_class_name': 'unit__to_node',\n",
    "                    'Object_class': 'unit',\n",
    "                    'Object_name': unit,\n",
    "                    'Node': output_value,\n",
    "                    'Parameter': 'minimum_operating_point',\n",
    "                    'Value': minimum_op_output\n",
    "                })\n",
    "\n",
    "# Create a new DataFrame from the transformed data\n",
    "df_unit_relation_parameter_data = pd.DataFrame(unit_relation_parameter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD ADDITIONAL ELECTRICITY CONNECTIONS IF NOT ALREADY EXISTENT ###\n",
    "units = df_units.iloc[:, 0].tolist()\n",
    "length = len(units)\n",
    "data = {\n",
    "    \"Relationship_class_name\": [\"unit__from_node\"] * length,\n",
    "    \"Object_class\": [\"unit\"] * length,\n",
    "    \"Object_name\": units,\n",
    "    \"Node\": [\"Power_Kasso\"] * length\n",
    "}\n",
    "df_electricity = pd.DataFrame(data)\n",
    "\n",
    "units_with_from_node = df_unit_relation_parameter_data[df_unit_relation_parameter_data['Relationship_class_name'].str.contains('unit__from_node')]\n",
    "valid_object_names = units_with_from_node['Object_name']\n",
    "df_electricity_filtered = df_electricity[df_electricity['Object_name'].isin(valid_object_names)]\n",
    "\n",
    "merged_df = pd.merge(df_electricity_filtered, units_with_from_node, on=['Relationship_class_name', 'Object_class', 'Object_name', 'Node'], how='left', indicator=True)\n",
    "df_electricity_nodes = merged_df[merged_df['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "df_unit_relation_parameter_data = pd.concat([df_unit_relation_parameter_data, df_electricity_nodes], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031af12-8f24-49f5-8f5b-6526f0065433",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONNECTIONS ###\n",
    "\n",
    "# Initialize an empty list to store the transformed data\n",
    "connection_relation_parameter_data = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_model_connections.iterrows():\n",
    "    connection = row['Connection']\n",
    "\n",
    "    # Iterate over Input and Output columns\n",
    "    for i in range(1, 3):\n",
    "        input_col = f'Input{i}'\n",
    "        output_col = f'Output{i}'\n",
    "        cap_input_col = f'Cap_{input_col}_existing'\n",
    "        cap_output_col = f'Cap_{output_col}_existing'\n",
    "        vom_cost_input_col = f'vom_cost_{input_col}'\n",
    "        vom_cost_output_col = f'vom_cost_{output_col}'\n",
    "        start_up_output_col = f'start_up_{output_col}'\n",
    "        shut_down_output_col = f'shut_down_{output_col}'\n",
    "        #fom_cost_col = 'fom_cost' if i == 1 else None\n",
    "        #vom_cost_col = 'vom_cost' if i == 1 else None\n",
    "\n",
    "        # Check for Input columns\n",
    "        input_value = row[input_col]\n",
    "        input_capacity = row[cap_input_col]\n",
    "        vom_cost_input = row[vom_cost_input_col]\n",
    "\n",
    "        #fom_cost_value = row[fom_cost_col] if fom_cost_col else None\n",
    "        #vom_cost_value = row[vom_cost_col] if vom_cost_col else None\n",
    "\n",
    "        if pd.notna(input_value):\n",
    "            connection_relation_parameter_data.append({\n",
    "                'Relationship_class_name': 'connection__from_node',\n",
    "                'Object_class': 'connection',\n",
    "                'Object_name': connection,\n",
    "                'Node': input_value,\n",
    "                'Parameter': 'connection_capacity' if pd.notna(input_capacity) else '',\n",
    "                'Value': input_capacity if pd.notna(input_capacity) else ''\n",
    "            })\n",
    "        \n",
    "            if pd.notna(input_value) and pd.notna(vom_cost_input):\n",
    "                connection_relation_parameter_data.append({\n",
    "                    'Relationship_class_name': 'connection__from_node',\n",
    "                    'Object_class': 'connection',\n",
    "                    'Object_name': connection,\n",
    "                    'Node': input_value,\n",
    "                    'Parameter': 'vom_cost',\n",
    "                    'Value': vom_cost_input\n",
    "                })\n",
    "\n",
    "        # Check for Output columns\n",
    "        output_value = row[output_col]\n",
    "        output_capacity = row[cap_output_col]\n",
    "        vom_cost_output = row[vom_cost_output_col]\n",
    "\n",
    "        '''if pd.notna(output_value):\n",
    "            connection_relation_parameter_data.append({\n",
    "                'Relationship_class_name': 'connection__to_node',\n",
    "                'Object_class': 'connection',\n",
    "                'Object_name': connection,\n",
    "                'Node': output_value,\n",
    "                'Parameter': 'connection_capacity' if pd.notna(output_capacity) else '',\n",
    "                'Value': output_capacity if pd.notna(output_capacity) else '',\n",
    "                #'fom_cost': fom_cost_value if pd.notna(fom_cost_value) else '',\n",
    "                #'vom_cost': vom_cost_value if pd.notna(vom_cost_value) else ''\n",
    "            })'''\n",
    "\n",
    "        if pd.notna(output_value):\n",
    "            connection_relation_parameter_data.append({\n",
    "                'Relationship_class_name': 'connection__to_node',\n",
    "                'Object_class': 'connection',\n",
    "                'Object_name': connection,\n",
    "                'Node': output_value,\n",
    "                'Parameter': 'connection_capacity' if pd.notna(output_capacity) else '',\n",
    "                'Value': output_capacity if pd.notna(output_capacity) else ''\n",
    "            })\n",
    "        \n",
    "        if pd.notna(output_value) and pd.notna(vom_cost_output):\n",
    "            connection_relation_parameter_data.append({\n",
    "                'Relationship_class_name': 'connection__to_node',\n",
    "                'Object_class': 'connection',\n",
    "                'Object_name': connection,\n",
    "                'Node': output_value,\n",
    "                'Parameter': 'vom_cost',\n",
    "                'Value': vom_cost_output\n",
    "            })\n",
    "\n",
    "#Create a new DataFrame from the transformed data\n",
    "df_connection_relation_parameter_data = pd.DataFrame(connection_relation_parameter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d8c41c-8fb4-4a60-883b-94b70f5ace80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create combined DataFrame:\n",
    "df_object__node = pd.concat([df_unit_relation_parameter_data, df_connection_relation_parameter_data])\n",
    "df_object__node = df_object__node.reset_index(drop=True)\n",
    "\n",
    "#show df head for control\n",
    "df_object__node.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1391f-d8cd-45dd-9867-7aefa0327740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a DataFrame for the definition of the object_node relationsships\n",
    "df_object__node_definitions = pd.DataFrame(df_object__node[['Relationship_class_name', 'Object_class', 'Object_name', 'Node']])\n",
    "df_object__node_definitions = df_object__node_definitions.drop_duplicates()\n",
    "df_object__node_definitions = df_object__node_definitions.reset_index(drop=True)\n",
    "\n",
    "# Drop rows whereno parameters for the relationship are defined (column has missing values (NaN or None))\n",
    "drop_no_vaule_column = 'Parameter'\n",
    "df_object__node_values = df_object__node[df_object__node[drop_no_vaule_column] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebeb807-b807-4882-b8cd-67a174c8edbd",
   "metadata": {},
   "source": [
    "Object__node_node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5a160-3f18-4656-82ee-484e7e703cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define which columns to check\n",
    "columns_In_In_Unit = ['Unit', 'Input1', 'Input2']\n",
    "columns_In_Out_Unit = ['Unit', 'Input1', 'Output1']\n",
    "columns_Out_Out_Unit = ['Unit', 'Output1', 'Output2']\n",
    "columns_In_In_Connection = ['Connection', 'Input1', 'Input2']\n",
    "columns_In_Out_Connection = ['Connection', 'Input1', 'Output1']\n",
    "columns_Out_Out_Connection = ['Connection', 'Output1', 'Output2']\n",
    "columns_Out_In_Connection = ['Connection', 'Output1', 'Input1']\n",
    "\n",
    "####UNITS#####\n",
    "#create list of tuples with values of cells + fix_ratio_XXX_XXX\n",
    "values_in_in_units = [('unit__node__node', 'unit', row[columns_In_In_Unit[0]], row[columns_In_In_Unit[1]], row[columns_In_In_Unit[2]], \n",
    "                       'fix_ratio_in_in_unit_flow', row['Relation_In_In']) \n",
    "                      if not pd.isnull(row[columns_In_In_Unit]).any() else (np.nan, np.nan, None) for _, row in df_model_units.iterrows() \n",
    "                      if not pd.isnull(row[columns_In_In_Unit]).any()]\n",
    "values_in_out_units = [('unit__node__node', 'unit', row[columns_In_Out_Unit[0]], row[columns_In_Out_Unit[1]], row[columns_In_Out_Unit[2]], \n",
    "                        'fix_ratio_in_out_unit_flow', row['Relation_In_Out']) \n",
    "                      if not pd.isnull(row[columns_In_Out_Unit]).any() else (np.nan, np.nan, None) for _, row in df_model_units.iterrows() \n",
    "                      if not pd.isnull(row[columns_In_Out_Unit]).any()]\n",
    "values_out_out_units = [('unit__node__node', 'unit', row[columns_Out_Out_Unit[0]], row[columns_Out_Out_Unit[1]], row[columns_Out_Out_Unit[2]], \n",
    "                         'fix_ratio_out_out_unit_flow', row['Relation_Out_Out']) \n",
    "                      if not pd.isnull(row[columns_Out_Out_Unit]).any() else (np.nan, np.nan, None) for _, row in df_model_units.iterrows() \n",
    "                      if not pd.isnull(row[columns_Out_Out_Unit]).any()]\n",
    "\n",
    "df_fix_ratio_in_in_units = pd.DataFrame(values_in_in_units, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                     'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_in_out_units = pd.DataFrame(values_in_out_units, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                       'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_out_out_units = pd.DataFrame(values_out_out_units, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                         'Node2', 'Parameter', 'Value'])\n",
    "\n",
    "####CONNECTIONS\n",
    "values_in_in_connections = [('connection__node__node', 'connection', row[columns_In_In_Connection[0]], \n",
    "                             row[columns_In_In_Connection[1]], row[columns_In_In_Connection[2]], \n",
    "                             'fix_ratio_in_in_connection_flow', row['Relation_In_In']) \n",
    "                            if not pd.isnull(row[columns_In_In_Connection]).any() else (np.nan, np.nan, None) for _, row in df_model_connections.iterrows() \n",
    "                            if not pd.isnull(row[columns_In_In_Connection]).any()]\n",
    "values_in_out_connections = [('connection__node__node', 'connection', row[columns_In_Out_Connection[0]], \n",
    "                              row[columns_In_Out_Connection[1]], row[columns_In_Out_Connection[2]], \n",
    "                              'fix_ratio_in_out_connection_flow', row['Relation_In_Out']) \n",
    "                             if not pd.isnull(row[columns_In_Out_Connection]).any() else (np.nan, np.nan, None) for _, row in df_model_connections.iterrows() \n",
    "                             if not pd.isnull(row[columns_In_Out_Connection]).any()]\n",
    "values_out_out_connections = [('connection__node__node', 'connection', row[columns_Out_Out_Connection[0]], \n",
    "                               row[columns_Out_Out_Connection[1]], row[columns_Out_Out_Connection[2]], \n",
    "                               'fix_ratio_out_out_connection_flow', row['Relation_Out_Out']) \n",
    "                              if not pd.isnull(row[columns_Out_Out_Connection]).any() else (np.nan, np.nan, None) for _, row in df_model_connections.iterrows() \n",
    "                              if not pd.isnull(row[columns_Out_Out_Connection]).any()]\n",
    "values_out_in_connections = [('connection__node__node', 'connection', row[columns_Out_In_Connection[0]], \n",
    "                               row[columns_Out_In_Connection[1]], row[columns_Out_In_Connection[2]], \n",
    "                               'fix_ratio_out_in_connection_flow', row['Relation_Out_In']) \n",
    "                              if not pd.isnull(row[columns_Out_In_Connection]).any() else (np.nan, np.nan, None) for _, row in df_model_connections.iterrows() \n",
    "                              if not pd.isnull(row[columns_Out_In_Connection]).any()]\n",
    "\n",
    "df_fix_ratio_in_in_connections = pd.DataFrame(values_in_in_connections, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                                 'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_in_out_connections = pd.DataFrame(values_in_out_connections, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                                   'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_out_out_connections = pd.DataFrame(values_out_out_connections, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                                     'Node2', 'Parameter', 'Value'])\n",
    "df_fix_ratio_out_in_connections = pd.DataFrame(values_out_in_connections, columns=['Relationship', 'Object_class', 'Object_name', 'Node1', \n",
    "                                                                                     'Node2', 'Parameter', 'Value'])\n",
    "\n",
    "#create Object_node_node\n",
    "df_object_node_node = pd.concat([df_fix_ratio_in_in_units, df_fix_ratio_in_out_units, df_fix_ratio_out_out_units, \n",
    "                                df_fix_ratio_in_in_connections, df_fix_ratio_in_out_connections, \n",
    "                                df_fix_ratio_out_out_connections, df_fix_ratio_out_in_connections])\n",
    "df_object_node_node = df_object_node_node.reset_index(drop=True)\n",
    "\n",
    "df_object_node_node = df_object_node_node.dropna(subset=['Value'])\n",
    "\n",
    "#for storages, the out_in_connetion is set in both directions\n",
    "# Check if the 'Object' column contains the word 'storage'\n",
    "storage_condition = df_object_node_node['Object_name'].str.contains('storage', case=False)\n",
    "\n",
    "# Filter rows that meet the condition\n",
    "storage_rows = df_object_node_node[storage_condition]\n",
    "\n",
    "# Add a new row with mirrored Node1 and Node2 for each matching row\n",
    "for index, row in storage_rows.iterrows():\n",
    "    mirrored_row = row.copy()\n",
    "    mirrored_row['Node1'], mirrored_row['Node2'] = row['Node2'], row['Node1']\n",
    "    df_object_node_node = pd.concat([df_object_node_node, mirrored_row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecebeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD UNIT__NODE__NODE RELATIONSHIPS FOR UNIT_IDLE_HEAT_RATE ###\n",
    "in_and_outputs = df_model_units.iloc[:, [0, 1, 3, 35]].copy()\n",
    "length = len(in_and_outputs)\n",
    "data = {\n",
    "    \"Relationship\": [\"unit__node__node\"] * length,\n",
    "    \"Object_class\": [\"unit\"] * length,\n",
    "    \"Object_name\": in_and_outputs.iloc[:, 0].tolist(),\n",
    "    \"Node1\": [\"Power_Kasso\"] * length,\n",
    "    \"Node2\": in_and_outputs.iloc[:, 2].tolist(),\n",
    "    \"Parameter\": [\"unit_idle_heat_rate\"] * length,\n",
    "    \"Value\": in_and_outputs.iloc[:, 3].tolist()\n",
    "}\n",
    "df_idle_node_node = pd.DataFrame(data)\n",
    "#drop all rows that now have input and output of electricity\n",
    "df_electricity_node_node = df_idle_node_node[df_idle_node_node['Node1'] != df_idle_node_node['Node2']]\n",
    "#drop all rows that do not have a unit_idle_heat rate\n",
    "df_electricity_node_node = df_electricity_node_node.dropna(subset=['Value'])\n",
    "\n",
    "df_object_node_node = pd.concat([df_object_node_node, df_electricity_node_node], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add unit_node_node relationships for every unit that has power as output\n",
    "df_non_electricity_node_node = df_idle_node_node[df_idle_node_node['Node1'] == df_idle_node_node['Node2']].copy()\n",
    "df_non_electricity_node_node.loc[:, 'Node1'] = df_non_electricity_node_node['Object_name'] + '_node'\n",
    "\n",
    "#drop all rows that do not have a unit_idle_heat rate\n",
    "df_non_electricity_node_node = df_non_electricity_node_node.dropna(subset=['Value'])\n",
    "\n",
    "df_object_node_node = pd.concat([df_object_node_node, df_non_electricity_node_node], ignore_index=True)\n",
    "df_non_electricity_node_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new [arbitrary] nodes to definition\n",
    "new_nodes = df_non_electricity_node_node['Node1']\n",
    "new_nodes = new_nodes[~new_nodes.isin(df_nodes['Object_Name'])]\n",
    "df_new_nodes = pd.DataFrame({\n",
    "    'Object_Name': new_nodes,\n",
    "    'Category': 'node'\n",
    "})\n",
    "\n",
    "df_nodes = pd.concat([df_nodes, df_new_nodes], ignore_index=True)\n",
    "# add new node to definition\n",
    "df_definition = pd.concat([df_definition, df_new_nodes], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new unit_to_nodes relationship with new nodes\n",
    "df_new = df_non_electricity_node_node.copy()\n",
    "df_new = df_new.iloc[:, :4]\n",
    "new_headers = ['Relationship_class_name', 'Object_class', 'Object_name', 'Node']\n",
    "df_new.columns = new_headers\n",
    "df_new.iloc[:, 0] = \"unit__from_node\"\n",
    "\n",
    "df_object__node_definitions = pd.concat([df_object__node_definitions, df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6da153",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add unit_incremental_heat_rates of 0 if not otherwise specified\n",
    "values_to_exclude = df_variable_efficiency.values.flatten()\n",
    "df_electricity_not = df_electricity_node_node[~df_electricity_node_node['Node2'].isin(values_to_exclude)]\n",
    "df_electricity_not = df_electricity_not.iloc[:,[0,1,2,3,4]]\n",
    "df_electricity_not['Parameter'] = 'unit_incremental_heat_rate'\n",
    "df_electricity_not['Value'] = 0\n",
    "\n",
    "#concat to object__node_node\n",
    "df_object_node_node = pd.concat([df_object_node_node, df_electricity_not], ignore_index=True)\n",
    "\n",
    "#show df head for control\n",
    "df_electricity_not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be54c5-1d66-4841-a002-30a94697b84e",
   "metadata": {},
   "source": [
    "#### Variable Efficiency Units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variable_efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the object__node_values for the relationship\n",
    "df_boolean_relations = create_ordered_unit_flow(df_variable_efficiency, 'unit__from_node')\n",
    "df_boolean_relations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b06362-af38-4e4b-ab1b-fc2f8024bee0",
   "metadata": {},
   "source": [
    "#### Demand and Renewables Availability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc1b34-e4e6-4187-8299-e66590b125d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table headers and relations\n",
    "column_names_1 = {'DateTime '+area: [None, None],\n",
    "                'Hydrogen_Kasso': ['node','demand'], \n",
    "                'E-Methanol_Kasso': ['node','demand'], \n",
    "                'Solar_Plant_Kasso': ['unit','unit_availability_factor']}\n",
    "df_blank_table_1 = pd.DataFrame(column_names_1, index=None)\n",
    "#add values\n",
    "df_temp_1 = pd.DataFrame(columns=['DateTime ' + area, 'Hydrogen_Kasso', 'E-Methanol_Kasso', 'Solar_Plant_Kasso'])\n",
    "\n",
    "df_temp_1['DateTime '+area] = df_time\n",
    "df_temp_1['Hydrogen_Kasso'] = 0\n",
    "df_temp_1['E-Methanol_Kasso'] = 25\n",
    "df_temp_1['Solar_Plant_Kasso'] = df_PV_availabilityfactors_values['unit_availability_factor']\n",
    "\n",
    "df_table_1 = pd.concat([df_blank_table_1, df_temp_1])\n",
    "#show table head for control\n",
    "df_table_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e74f16-846f-4ba0-b9c6-869e32be6676",
   "metadata": {},
   "source": [
    "#### Energy prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785d20b-2cbe-4f0b-8842-2878a3335580",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_2 = {'DateTime ' + area: ['relationship class','connection','node','parameter name'],\n",
    "                'Power_Wholesale_In': ['connection__from_node','power_line_Wholesale_Kasso','Power_Wholesale','connection_flow_cost'], \n",
    "                'Power_Wholesale_Out': ['connection__to_node','power_line_Wholesale_Kasso','Power_Wholesale','connection_flow_cost'], \n",
    "                'District_Heating': ['connection__to_node','pipeline_District_Heating','District_Heating','connection_flow_cost']}\n",
    "df_blank_table_2 = pd.DataFrame(column_names_2, index=None)\n",
    "df_temp_2 = pd.DataFrame(columns=['DateTime ' + area, 'Power_Wholesale_In', 'Power_Wholesale_Out', 'District_Heating'])\n",
    "\n",
    "df_temp_2['DateTime ' + area] = df_time\n",
    "df_temp_2['Power_Wholesale_In'] = df_powerprices_values['SpotPriceEUR']\n",
    "df_temp_2['Power_Wholesale_Out'] = -1 * df_powerprices_values['SpotPriceEUR']\n",
    "df_temp_2['District_Heating'] = 0\n",
    "\n",
    "df_table_2 = pd.concat([df_blank_table_2, df_temp_2], ignore_index=True)\n",
    "#show table head for control\n",
    "df_table_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df00bdab-f254-437f-b78d-d32b19e2f9db",
   "metadata": {},
   "source": [
    "#### Time Series Storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date index\n",
    "before = start_date-timedelta(hours=1)\n",
    "date_index_beginning = pd.date_range(start=before, end=start_date, freq='H')\n",
    "formatted_beginning = date_index_beginning.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "df_formatted_beginning = pd.DataFrame(formatted_beginning, columns=['DateTime'])\n",
    "df_time_beginning = pd.DataFrame(df_formatted_beginning)\n",
    "#add one blank row\n",
    "new_row = pd.Series([])\n",
    "df_time_beginning = pd.concat([pd.DataFrame([new_row]), df_time_beginning]).reset_index(drop=True)\n",
    "\n",
    "#concat raw data with time index\n",
    "storage_values = df_model_storages.iloc[:,[0, 1, 2, 6]]\n",
    "storage_values = storage_values.iloc[:, [0, 3, 1, 2]]\n",
    "storage_values_transposed = storage_values.T\n",
    "storage_values_transposed.columns = storage_values_transposed.iloc[0]\n",
    "storage_values_transposed = storage_values_transposed[1:]\n",
    "storage_values_transposed.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_storage = pd.concat([df_time_beginning, storage_values_transposed], axis=1)\n",
    "#show table head for control\n",
    "df_storage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b971c4",
   "metadata": {},
   "source": [
    "#### Model relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf465d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing definition of model components\n",
    "column_names_model_components = {'Object_class_name':['model','temporal_block','stochastic_scenario', 'stochastic_structure', 'report'],\n",
    "                      'Object_name': [model_name, temporal_block, stochastic_scenario, stochastic_structure, report_name]}\n",
    "df_model_components = pd.DataFrame(column_names_model_components, index=None)\n",
    "#outputs:\n",
    "df_outputs = pd.DataFrame({\n",
    "    'Object_class_name': ['output']*len(reports),\n",
    "    'Object_name': reports\n",
    "})\n",
    "df_model_components = pd.concat([df_model_components, df_outputs], axis=0)\n",
    "df_model_components = df_model_components.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reports\n",
    "column_names_model_structure = {'Object_class_name':['model','temporal_block','stochastic_scenario', 'stochastic_structure', 'report'],\n",
    "                      'Object_name': [model_name, temporal_block, stochastic_scenario, stochastic_structure, report_name]}\n",
    "df_reports = pd.DataFrame({\n",
    "    'Relationship_class_name': ['report__output']*len(reports),\n",
    "    'Object_class_name_1': ['report']*len(reports),\n",
    "    'Object_class_name_2': ['output']*len(reports),\n",
    "    'Object_name_1': [report_name]*len(reports),\n",
    "    'Object_name_2': reports\n",
    "})\n",
    "#everything else\n",
    "df_model_struc = pd.DataFrame({\n",
    "    'Relationship_class_name': ['model__temporal_block','model__default_temporal_block', \n",
    "                                'model__stochastic_structure', 'model__default_stochastic_structure',\n",
    "                                'stochastic_structure__stochastic_scenario', 'model__report'],\n",
    "    'Object_class_name_1': ['model','model','model','model','stochastic_structure','model'],\n",
    "    'Object_class_name_2': ['temporal_block', 'temporal_block','stochastic_structure','stochastic_structure', 'stochastic_scenario','report'],\n",
    "    'Object_name_1': [model_name, model_name,model_name,model_name,stochastic_structure, model_name],\n",
    "    'Object_name_2': [temporal_block, temporal_block, stochastic_structure, stochastic_structure, stochastic_scenario, report_name]\n",
    "})\n",
    "df_model_relations = pd.concat([df_model_struc, df_reports], axis=0)\n",
    "df_model_relations = df_model_relations.reset_index(drop=True)\n",
    "#show table head for control\n",
    "df_model_relations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b88dc-3a5b-41c5-b184-64593c28c72c",
   "metadata": {},
   "source": [
    "#### Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960d14b-394b-4599-9e1e-8831aa59e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### take first 3 columns and add another table with \"Alternative\", \"Value\"\n",
    "column_names_model = {'Object_class_name':['model','model','temporal_block'],\n",
    "                      'Object_name': [model_name, model_name, temporal_block],\n",
    "                      'Parameter':['model_start','model_end','resolution'],\n",
    "                      'Alternative': [scenario, scenario, scenario],\n",
    "                      'Value': ['{\"type\": \"date_time\", \"data\": \"'+df_time.iloc[0]['DateTime']+'\"}',\n",
    "                          '{\"type\": \"date_time\", \"data\": \"'+df_time.iloc[-1]['DateTime']+'\"}', \n",
    "                          '{\"type\":\"duration\", \"data\": \"'+frequency+'\"}']}\n",
    "df_model = pd.DataFrame(column_names_model, index=None)\n",
    "#show table head for control\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dfbf3e-1928-4547-8b3a-dac782ca46a3",
   "metadata": {},
   "source": [
    "### Creating one combined excel and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523a4cd-ad6f-44d6-993d-3ebaf00680c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the prepared input excel for the use in SpineToolbox\n",
    "with pd.ExcelWriter(output_file_path + output_file_name) as writer:\n",
    "    df_definition.to_excel(writer, sheet_name='Definition', index=False)\n",
    "    unit_parameters_rest_df.to_excel(writer, sheet_name='Definition_parameters', index=False)\n",
    "    unit_parameters_duration_df.to_excel(writer, sheet_name='Definition_parameters_duration', index=False)\n",
    "    df_nodes.to_excel(writer, sheet_name='Nodes', index=False)\n",
    "    df_connections.to_excel(writer, sheet_name='Connections', index=False)\n",
    "    df_object__node_definitions.to_excel(writer, sheet_name='Object__to_from_node_definition', index=False)\n",
    "    df_object__node_values.to_excel(writer, sheet_name='Object__to_from_node', index=False)\n",
    "    df_boolean_relations.to_excel(writer, sheet_name='Boolean_relations', index=False)\n",
    "    df_object_node_node.to_excel(writer, sheet_name='Object__node_node', index=False)\n",
    "    df_variable_efficiency.to_excel(writer, sheet_name='Variable_Eff', index=False)\n",
    "    df_storage.to_excel(writer, sheet_name='Time_series_storage', index=False)\n",
    "    df_table_1.to_excel(writer, sheet_name='Demand', index=False)\n",
    "    df_table_2.to_excel(writer, sheet_name='Energy_prices', index=False)\n",
    "    df_model_components.to_excel(writer, sheet_name='Model_components', index=False)\n",
    "    df_model_relations.to_excel(writer, sheet_name='Model_relations', index=False)\n",
    "    df_model.to_excel(writer, sheet_name='Model', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecfd010-a65f-4cfc-8ec2-a7d3bbded502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
